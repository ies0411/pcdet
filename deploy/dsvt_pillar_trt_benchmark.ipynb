{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5367841a-db44-47da-ac41-923c5f82f4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "# 코드에서 nms제외해야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "497f97aa-ab6b-45e0-9688-83d7ff07e2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install onnxruntime\n",
    "# !pip install onnx onnxconverter-common\n",
    "# !pip install -U onnxruntime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "770ea0b4-0a87-4f8b-8366-6f1641d1fc73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: detected dubious ownership in repository at '/mnt/nas2/users/eslim/workspace/OpenPCDet'\n",
      "To add an exception for this directory, call:\n",
      "\n",
      "\tgit config --global --add safe.directory /mnt/nas2/users/eslim/workspace/OpenPCDet\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorrt as trt\n",
    "import torch\n",
    "from pcdet.config import cfg, cfg_from_yaml_file\n",
    "from pcdet.models import build_network\n",
    "from pcdet.datasets import build_dataloader\n",
    "from pcdet.utils import common_utils\n",
    "# import pycuda.driver as cuda\n",
    "# import pycuda.autoinit\n",
    "# import torch_tensorrt\n",
    "\n",
    "# import pycuda.driver as cuda\n",
    "# import pycuda.autoinit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea8aedf6-2698-4a84-9dc6-0f914e4c1e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-16 13:26:14,949   INFO  Loading Custom dataset.\n",
      "2024-04-16 13:26:14,951   INFO  Total samples for CUSTOM dataset: 0\n",
      "2024-04-16 13:26:17,150   INFO  ==> Loading parameters from checkpoint ./pillar/model.pth to GPU\n",
      "2024-04-16 13:26:17,268   INFO  ==> Checkpoint trained from version: pcdet+0.6.0+255db8f\n",
      "2024-04-16 13:26:17,310   INFO  ==> Done (loaded 391/391)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cfg_file = \"./pillar/config.yaml\"\n",
    "cfg_from_yaml_file(cfg_file, cfg)\n",
    "if os.path.exists('./deploy_pillar_sfaw_bm')==False:\n",
    "    os.mkdir('./deploy_pillar_sfaw_bm')\n",
    "log_file = './deploy_pillar_sfaw_bm/log_trt.log'\n",
    "\n",
    "logger = common_utils.create_logger(log_file, rank=0)\n",
    "test_set, test_loader, sampler = build_dataloader(\n",
    "    dataset_cfg=cfg.DATA_CONFIG,\n",
    "    class_names=cfg.CLASS_NAMES,\n",
    "    batch_size=1,\n",
    "    dist=False, workers=8, logger=logger, training=False\n",
    ")\n",
    "\n",
    "model = build_network(model_cfg=cfg.MODEL, num_class=len(cfg.CLASS_NAMES), dataset=test_set)\n",
    "ckpt = \"./pillar/model.pth\"\n",
    "\n",
    "model.load_params_from_file(filename=ckpt, logger=logger, to_cpu=False, pre_trained_path=None)\n",
    "model.eval()\n",
    "model.cuda()\n",
    "####### load model #######\n",
    "\n",
    "####### read input #######\n",
    "batch_dict = torch.load(\"/mnt/nas2/users/eslim/onnx/sfaw/input_dict.pth\", map_location=\"cuda\")\n",
    "inputs = batch_dict\n",
    "# inputs_vfe = model.vfe(inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04f01935-fb7e-4baa-b925-8ce9c77c9da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trt_engine(path: str) -> trt.ICudaEngine:\n",
    "    \"\"\"Deserialize TensorRT engine from disk.\n",
    "\n",
    "    Args:\n",
    "        path (str): The disk path to read the engine.\n",
    "\n",
    "    Returns:\n",
    "        tensorrt.ICudaEngine: The TensorRT engine loaded from disk.\n",
    "    \"\"\"\n",
    "    # load_tensorrt_plugin()\n",
    "    with trt.Logger() as logger, trt.Runtime(logger) as runtime:\n",
    "        with open(path, mode='rb') as f:\n",
    "            engine_bytes = f.read()\n",
    "        engine = runtime.deserialize_cuda_engine(engine_bytes)\n",
    "        print(f\"TensorRT engine {path} successfully loaded.\")\n",
    "        return engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7216823-eba6-4339-a065-596acbdc2857",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_context(engine):\n",
    "\n",
    "    trt.init_libnvinfer_plugins(None, '')\n",
    "    if isinstance(trt_path, str):\n",
    "        engine = load_trt_engine(trt_path)\n",
    "    \n",
    "    if not isinstance(engine, trt.ICudaEngine):\n",
    "        raise TypeError(f'`engine` should be str or trt.ICudaEngine, \\\n",
    "            but given: {type(engine)}')\n",
    "    \n",
    "    context = engine.create_execution_context()\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8568c94-f0ae-4956-b222-a29e89eba1f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorRT engine ./deploy_pillar_sfaw_3d_origin/dsvt_3d_bb_origin_2.engine successfully loaded.\n",
      "TensorRT engine ./deploy_pillar_sfaw_3d_origin/dsvt_3d_bb_origin_2.engine successfully loaded.\n",
      "[04/16/2024-13:26:18] [TRT] [W] CUDA lazy loading is not enabled. Enabling it can significantly reduce device memory usage and speed up TensorRT initialization. See \"Lazy Loading\" section of CUDA documentation https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#lazy-loading\n"
     ]
    }
   ],
   "source": [
    "# context.set_tensor_address(\"src\", ptr)\n",
    "trt_path = './deploy_pillar_sfaw_3d_origin/dsvt_3d_bb_origin_2.engine'\n",
    "engine = load_trt_engine(trt_path)\n",
    "context = load_context(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc9e7635-abd0-4697-8992-91cecb2b6479",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07900428771972656\n"
     ]
    }
   ],
   "source": [
    "input_names = [\n",
    "    'src',\n",
    "    'set_voxel_inds_tensor_shift_0', \n",
    "    'set_voxel_inds_tensor_shift_1', \n",
    "    'set_voxel_masks_tensor_shift_0', \n",
    "    'set_voxel_masks_tensor_shift_1',\n",
    "    'pos_embed_tensor'\n",
    "]\n",
    "output_names = [\"output\",]\n",
    "\n",
    "DSVT_Backbone = model.backbone_3d\n",
    "dsvtblocks_list = DSVT_Backbone.stage_0\n",
    "layer_norms_list = DSVT_Backbone.residual_norm_stage_0\n",
    "\n",
    "inputs_vfe = model.vfe(inputs)\n",
    "import time\n",
    "start_time = time.time()\n",
    "inputs_3d = model.backbone_3d(inputs_vfe)\n",
    "print(time.time()-start_time)\n",
    "voxel_info = DSVT_Backbone.input_layer(inputs_vfe)\n",
    "voxel_feat = voxel_info['voxel_feats_stage0']\n",
    "\n",
    "pillar_features = inputs_vfe['voxel_features']\n",
    "set_voxel_inds_list = [[voxel_info[f'set_voxel_inds_stage{s}_shift{i}'] for i in range(2)] for s in range(1)]\n",
    "set_voxel_masks_list = [[voxel_info[f'set_voxel_mask_stage{s}_shift{i}'] for i in range(2)] for s in range(1)]\n",
    "pos_embed_list = [[[voxel_info[f'pos_embed_stage{s}_block{b}_shift{i}'] for i in range(2)] for b in range(4)] for s in range(1)]\n",
    "\n",
    "output = voxel_feat\n",
    "inputs = dict(\n",
    "        src=output,\n",
    "        set_voxel_inds_tensor_shift_0=set_voxel_inds_list[0][0].int(),\n",
    "        set_voxel_inds_tensor_shift_1=set_voxel_inds_list[0][1].int(),\n",
    "        set_voxel_masks_tensor_shift_0=set_voxel_masks_list[0][0],\n",
    "        set_voxel_masks_tensor_shift_1=set_voxel_masks_list[0][1],\n",
    "        pos_embed_tensor=torch.stack([torch.stack(v, dim=0) for v in pos_embed_list[0]], dim=0),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "497d0c72-81c4-4ec1-a5d4-30e60288239b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "profile : [(962, 192), (962, 192), (962, 192)]\n",
      "type : torch.float32\n",
      "shape : torch.Size([962, 192])\n",
      "profile : [(2, 40, 36), (2, 40, 36), (2, 40, 36)]\n",
      "type : torch.int32\n",
      "shape : torch.Size([2, 40, 36])\n",
      "profile : [(2, 34, 36), (2, 34, 36), (2, 34, 36)]\n",
      "type : torch.int32\n",
      "shape : torch.Size([2, 34, 36])\n",
      "profile : [(2, 40, 36), (2, 40, 36), (2, 40, 36)]\n",
      "type : torch.bool\n",
      "shape : torch.Size([2, 40, 36])\n",
      "profile : [(2, 34, 36), (2, 34, 36), (2, 34, 36)]\n",
      "type : torch.bool\n",
      "shape : torch.Size([2, 34, 36])\n",
      "profile : [(4, 2, 962, 192), (4, 2, 962, 192), (4, 2, 962, 192)]\n",
      "type : torch.float32\n",
      "shape : torch.Size([4, 2, 962, 192])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3265058/1391992233.py:7: DeprecationWarning: Use get_tensor_profile_shape instead.\n",
      "  profile = engine.get_profile_shape(profile_id,input_name)\n"
     ]
    }
   ],
   "source": [
    "bindings = [None] * (len(input_names) + len(output_names))\n",
    "\n",
    "# https://github.dev/Haiyang-W/DSVT , dsvt.py -> 384line\n",
    "profile_id = 0\n",
    "idx = 0\n",
    "for input_name, input_tensor in inputs.items():    \n",
    "    profile = engine.get_profile_shape(profile_id,input_name)\n",
    "    print(f'profile : {profile}')\n",
    "    print(f'type : {input_tensor.dtype}')\n",
    "    print(f'shape : {input_tensor.size()}')\n",
    "    context.set_input_shape(input_name,tuple(input_tensor.shape))\n",
    "    bindings[idx] = input_tensor.contiguous().data_ptr()\n",
    "    idx+=1\n",
    "# get_binding_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ff836cf-3242-4b63-b934-291f1358243e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[140227549069312,\n",
       " 140229592588288,\n",
       " 140229592600064,\n",
       " 140229597966848,\n",
       " 140229592652800,\n",
       " 140227393880064,\n",
       " None]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bindings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "386a6aab-5bb9-4a95-8bbe-80852b012ece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[140227549069312,\n",
       " 140229592588288,\n",
       " 140229592600064,\n",
       " 140229597966848,\n",
       " 140229592652800,\n",
       " 140227393880064,\n",
       " 140227549069312]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bindings[-1] = output.data_ptr()\n",
    "bindings\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1f0b133-b95d-4c5c-ab59-18561894d08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00435328483581543\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "context.execute_v2(bindings)\n",
    "print(time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a71c5274-a564-4345-8e2b-df039e41d081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7080,  0.1649,  0.0999,  ..., -1.1533,  0.0462, -0.0028],\n",
       "        [-0.7070,  0.1465,  0.1014,  ..., -1.1719,  0.0542,  0.0415],\n",
       "        [-0.8643,  0.3259,  0.1472,  ..., -1.1963,  0.1998,  0.0409],\n",
       "        ...,\n",
       "        [-0.3025,  0.1978,  0.0900,  ..., -1.1904,  0.0031,  0.1912],\n",
       "        [-0.2747,  0.3757,  0.1881,  ..., -1.3145, -0.2715,  0.0710],\n",
       "        [-0.2681,  0.2710,  0.2347,  ..., -1.1846,  0.1216, -0.0175]],\n",
       "       device='cuda:0', grad_fn=<CloneBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7ca02fa-a1df-4c7f-9f3c-071a3f5db451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorRT engine ./deploy_pillar_sfaw_2d/dsvt_2d_bb_2.engine successfully loaded.\n",
      "TensorRT engine ./deploy_pillar_sfaw_2d/dsvt_2d_bb_2.engine successfully loaded.\n",
      "[04/16/2024-13:26:19] [TRT] [W] CUDA lazy loading is not enabled. Enabling it can significantly reduce device memory usage and speed up TensorRT initialization. See \"Lazy Loading\" section of CUDA documentation https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#lazy-loading\n"
     ]
    }
   ],
   "source": [
    "# context.set_tensor_address(\"src\", ptr)\n",
    "trt_path = './deploy_pillar_sfaw_2d/dsvt_2d_bb_2.engine'\n",
    "engine = load_trt_engine(trt_path)\n",
    "context = load_context(engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98eedce5-b844-4418-ad59-2e359dffba5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_3d = model.backbone_3d(inputs_vfe)\n",
    "input_names = [\n",
    "    # 'voxel_features',\n",
    "    # 'use_lead_xyz',\n",
    "    # 'batch_size',\n",
    "    'pillar_features',\n",
    "    'voxel_coords',\n",
    "]\n",
    "output_names = [\"output\"]\n",
    "\n",
    "\n",
    "input_dict = {}\n",
    "input_dict['pillar_features'] = inputs_3d['pillar_features']\n",
    "input_dict['voxel_coords'] = inputs_3d['voxel_coords']\n",
    "output = torch.empty([1, 192, 468, 468]).to('cuda:0')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc8fef56-55b3-416d-81b9-9362252caa23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_name: pillar_features\n",
      "profile : [(962, 192), (962, 192), (962, 192)]\n",
      "type : torch.float32\n",
      "shape : torch.Size([962, 192])\n",
      "======\n",
      "convert long to int\n",
      "input_name: voxel_coords\n",
      "profile : [(962, 4), (962, 4), (962, 4)]\n",
      "type : torch.int32\n",
      "shape : torch.Size([962, 4])\n",
      "======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3265058/854044026.py:7: DeprecationWarning: Use get_tensor_profile_shape instead.\n",
      "  profile = engine.get_profile_shape(profile_id,input_name)\n"
     ]
    }
   ],
   "source": [
    "bindings = [None] * (len(input_names) + len(output_names))\n",
    "\n",
    "# https://github.dev/Haiyang-W/DSVT , dsvt.py -> 384line\n",
    "profile_id = 0\n",
    "idx = 0\n",
    "for input_name, input_tensor in input_dict.items():    \n",
    "    profile = engine.get_profile_shape(profile_id,input_name)\n",
    "    if input_tensor.dtype == torch.long:\n",
    "        input_tensor=input_tensor.int()\n",
    "        print(\"convert long to int\")\n",
    "    print(f'input_name: {input_name}')\n",
    "    print(f'profile : {profile}')\n",
    "    print(f'type : {input_tensor.dtype}')\n",
    "    print(f'shape : {input_tensor.size()}')\n",
    "    print(\"======\")\n",
    "    context.set_input_shape(input_name,tuple(input_tensor.shape))\n",
    "    bindings[idx] = input_tensor.contiguous().data_ptr()\n",
    "    idx+=1\n",
    "# get_binding_index\n",
    "bindings[-1] = output.data_ptr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49453542-79f1-4f67-8f0f-a26173ede6a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[140227289761280, 140227367413760, 140226588573696]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bindings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28fa85ff-bc4f-4132-bf0c-5fab06b2a1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.025560379028320312[04/16/2024-13:26:19] [TRT] [E] 1: [reformat.cpp::executeCutensor::331] Error Code 1: CuTensor (Internal cuTensor permutate execute failed)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "context.execute_v2(\n",
    "            bindings\n",
    "        )\n",
    "print(time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92da8ace-c119-423a-a5f9-2bfe34152c83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
