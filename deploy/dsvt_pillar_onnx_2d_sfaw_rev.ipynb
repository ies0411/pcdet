{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "072484a7-a5cb-40e0-9724-7f4126837e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install --upgrade onnx\n",
    "# !pip install onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "919f3bab-9a8a-44fe-b999-993169d4d8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class AllDSVTBlocksTRT(nn.Module):\n",
    "#     def __init__(self, dsvtblocks_list, layer_norms_list):\n",
    "#         super().__init__()\n",
    "#         self.layer_norms_list = layer_norms_list\n",
    "#         self.dsvtblocks_list = dsvtblocks_list\n",
    "#     def forward(\n",
    "#         self,\n",
    "#         pillar_features,\n",
    "#         set_voxel_inds_tensor_shift_0,\n",
    "#         set_voxel_inds_tensor_shift_1,\n",
    "#         set_voxel_masks_tensor_shift_0,\n",
    "#         set_voxel_masks_tensor_shift_1,\n",
    "#         pos_embed_tensor,\n",
    "#     ):\n",
    "#         outputs = pillar_features\n",
    "\n",
    "#         residual = outputs\n",
    "#         blc_id = 0\n",
    "#         set_id = 0\n",
    "#         set_voxel_inds = set_voxel_inds_tensor_shift_0[set_id:set_id+1].squeeze(0)\n",
    "#         set_voxel_masks = set_voxel_masks_tensor_shift_0[set_id:set_id+1].squeeze(0)\n",
    "#         pos_embed = pos_embed_tensor[blc_id:blc_id+1, set_id:set_id+1].squeeze(0).squeeze(0)\n",
    "#         # inputs = (outputs, set_voxel_inds, set_voxel_masks, pos_embed, True)\n",
    "#         inputs = (outputs, set_voxel_inds, set_voxel_masks, pos_embed)\n",
    "\n",
    "#         outputs = self.dsvtblocks_list[blc_id].encoder_list[set_id](*inputs)\n",
    "#         set_id = 1\n",
    "#         set_voxel_inds = set_voxel_inds_tensor_shift_0[set_id:set_id+1].squeeze(0)\n",
    "#         set_voxel_masks = set_voxel_masks_tensor_shift_0[set_id:set_id+1].squeeze(0)\n",
    "#         pos_embed = pos_embed_tensor[blc_id:blc_id+1, set_id:set_id+1].squeeze(0).squeeze(0)\n",
    "#         # inputs = (outputs, set_voxel_inds, set_voxel_masks, pos_embed, True)\n",
    "#         inputs = (outputs, set_voxel_inds, set_voxel_masks, pos_embed)\n",
    "\n",
    "#         outputs = self.dsvtblocks_list[blc_id].encoder_list[set_id](*inputs)\n",
    "\n",
    "#         outputs = self.layer_norms_list[blc_id](residual + outputs)\n",
    "\n",
    "#         residual = outputs\n",
    "#         blc_id = 1\n",
    "#         set_id = 0\n",
    "#         set_voxel_inds = set_voxel_inds_tensor_shift_1[set_id:set_id+1].squeeze(0)\n",
    "#         set_voxel_masks = set_voxel_masks_tensor_shift_1[set_id:set_id+1].squeeze(0)\n",
    "#         pos_embed = pos_embed_tensor[blc_id:blc_id+1, set_id:set_id+1].squeeze(0).squeeze(0)\n",
    "#         inputs = (outputs, set_voxel_inds, set_voxel_masks, pos_embed)\n",
    "#         # inputs = (outputs, set_voxel_inds, set_voxel_masks, pos_embed, True)\n",
    "\n",
    "#         outputs = self.dsvtblocks_list[blc_id].encoder_list[set_id](*inputs)\n",
    "#         set_id = 1\n",
    "#         set_voxel_inds = set_voxel_inds_tensor_shift_1[set_id:set_id+1].squeeze(0)\n",
    "#         set_voxel_masks = set_voxel_masks_tensor_shift_1[set_id:set_id+1].squeeze(0)\n",
    "#         pos_embed = pos_embed_tensor[blc_id:blc_id+1, set_id:set_id+1].squeeze(0).squeeze(0)\n",
    "#         inputs = (outputs, set_voxel_inds, set_voxel_masks, pos_embed)\n",
    "#         # inputs = (outputs, set_voxel_inds, set_voxel_masks, pos_embed, True)\n",
    "#         outputs = self.dsvtblocks_list[blc_id].encoder_list[set_id](*inputs)\n",
    "\n",
    "#         outputs = self.layer_norms_list[blc_id](residual + outputs)\n",
    "\n",
    "#         residual = outputs\n",
    "#         blc_id = 2\n",
    "#         set_id = 0\n",
    "#         set_voxel_inds = set_voxel_inds_tensor_shift_0[set_id:set_id+1].squeeze(0)\n",
    "#         set_voxel_masks = set_voxel_masks_tensor_shift_0[set_id:set_id+1].squeeze(0)\n",
    "#         pos_embed = pos_embed_tensor[blc_id:blc_id+1, set_id:set_id+1].squeeze(0).squeeze(0)\n",
    "#         # inputs = (outputs, set_voxel_inds, set_voxel_masks, pos_embed, True)\n",
    "#         inputs = (outputs, set_voxel_inds, set_voxel_masks, pos_embed)\n",
    "#         outputs = self.dsvtblocks_list[blc_id].encoder_list[set_id](*inputs)\n",
    "#         set_id = 1\n",
    "#         set_voxel_inds = set_voxel_inds_tensor_shift_0[set_id:set_id+1].squeeze(0)\n",
    "#         set_voxel_masks = set_voxel_masks_tensor_shift_0[set_id:set_id+1].squeeze(0)\n",
    "#         pos_embed = pos_embed_tensor[blc_id:blc_id+1, set_id:set_id+1].squeeze(0).squeeze(0)\n",
    "#         # inputs = (outputs, set_voxel_inds, set_voxel_masks, pos_embed, True)\n",
    "#         inputs = (outputs, set_voxel_inds, set_voxel_masks, pos_embed)\n",
    "#         outputs = self.dsvtblocks_list[blc_id].encoder_list[set_id](*inputs)\n",
    "\n",
    "#         outputs = self.layer_norms_list[blc_id](residual + outputs)\n",
    "\n",
    "#         residual = outputs\n",
    "#         blc_id = 3\n",
    "#         set_id = 0\n",
    "#         set_voxel_inds = set_voxel_inds_tensor_shift_1[set_id:set_id+1].squeeze(0)\n",
    "#         set_voxel_masks = set_voxel_masks_tensor_shift_1[set_id:set_id+1].squeeze(0)\n",
    "#         pos_embed = pos_embed_tensor[blc_id:blc_id+1, set_id:set_id+1].squeeze(0).squeeze(0)\n",
    "#         # inputs = (outputs, set_voxel_inds, set_voxel_masks, pos_embed, True)\n",
    "#         inputs = (outputs, set_voxel_inds, set_voxel_masks, pos_embed)\n",
    "#         outputs = self.dsvtblocks_list[blc_id].encoder_list[set_id](*inputs)\n",
    "#         set_id = 1\n",
    "#         set_voxel_inds = set_voxel_inds_tensor_shift_1[set_id:set_id+1].squeeze(0)\n",
    "#         set_voxel_masks = set_voxel_masks_tensor_shift_1[set_id:set_id+1].squeeze(0)\n",
    "#         pos_embed = pos_embed_tensor[blc_id:blc_id+1, set_id:set_id+1].squeeze(0).squeeze(0)\n",
    "#         inputs = (outputs, set_voxel_inds, set_voxel_masks, pos_embed)\n",
    "#         # inputs = (outputs, set_voxel_inds, set_voxel_masks, pos_embed, True)\n",
    "#         outputs = self.dsvtblocks_list[blc_id].encoder_list[set_id](*inputs)\n",
    "\n",
    "#         outputs = self.layer_norms_list[blc_id](residual + outputs)\n",
    "\n",
    "#         return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80f66a20-a14b-4980-93b4-21ebd5c2b60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: detected dubious ownership in repository at '/mnt/nas2/users/eslim/workspace/OpenPCDet'\n",
      "To add an exception for this directory, call:\n",
      "\n",
      "\tgit config --global --add safe.directory /mnt/nas2/users/eslim/workspace/OpenPCDet\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.onnx\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "from pcdet.config import cfg, cfg_from_yaml_file\n",
    "from pcdet.models import build_network\n",
    "from pcdet.datasets import build_dataloader\n",
    "from pcdet.utils import common_utils\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "# # import onnx\n",
    "import onnxruntime as ort\n",
    "import torch.nn as nn\n",
    "\n",
    "# from typing import Sequence, NamedTuple\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa75325f-2038-4319-9515-bd95bc9a5871",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-16 10:56:58,029   INFO  Loading Custom dataset.\n",
      "2024-04-16 10:56:58,030   INFO  Total samples for CUSTOM dataset: 0\n"
     ]
    }
   ],
   "source": [
    "# cfg_file = \"./onnx_config.yaml\"\n",
    "cfg_file = \"./pillar/config.yaml\"\n",
    "cfg_from_yaml_file(cfg_file, cfg)\n",
    "if os.path.exists('./deploy_pillar_sfaw_2d_rev')==False:\n",
    "    os.mkdir('./deploy_pillar_sfaw_2d_rev')\n",
    "log_file = './deploy_pillar_sfaw_2d_rev/log_trt.log'\n",
    "logger = common_utils.create_logger(log_file, rank=0)\n",
    "test_set, test_loader, sampler = build_dataloader(\n",
    "    dataset_cfg=cfg.DATA_CONFIG,\n",
    "    class_names=cfg.CLASS_NAMES,\n",
    "    batch_size=1,\n",
    "    dist=False, workers=8, logger=logger, training=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "657d9d46-db74-4033-9e7f-e1c66a0be44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-16 10:57:00,378   INFO  ==> Loading parameters from checkpoint ./pillar/model.pth to GPU\n",
      "2024-04-16 10:57:00,512   INFO  ==> Checkpoint trained from version: pcdet+0.6.0+255db8f\n",
      "2024-04-16 10:57:00,543   INFO  ==> Done (loaded 391/391)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CenterPoint(\n",
       "  (vfe): DynamicVoxelVFE(\n",
       "    (pfn_layers): ModuleList(\n",
       "      (0): PFNLayerV2(\n",
       "        (linear): Linear(in_features=10, out_features=96, bias=False)\n",
       "        (norm): BatchNorm1d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): PFNLayerV2(\n",
       "        (linear): Linear(in_features=192, out_features=192, bias=False)\n",
       "        (norm): BatchNorm1d(192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (backbone_3d): DSVT(\n",
       "    (input_layer): DSVTInputLayer(\n",
       "      (posembed_layers): ModuleList(\n",
       "        (0): ModuleList(\n",
       "          (0-3): 4 x ModuleList(\n",
       "            (0-1): 2 x PositionEmbeddingLearned(\n",
       "              (position_embedding_head): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=192, bias=True)\n",
       "                (1): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU(inplace=True)\n",
       "                (3): Linear(in_features=192, out_features=192, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (stage_0): ModuleList(\n",
       "      (0-3): 4 x DSVTBlock(\n",
       "        (encoder_list): ModuleList(\n",
       "          (0-1): 2 x DSVT_EncoderLayer(\n",
       "            (win_attn): SetAttention(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
       "              )\n",
       "              (linear1): Linear(in_features=192, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0, inplace=False)\n",
       "              (linear2): Linear(in_features=384, out_features=192, bias=True)\n",
       "              (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout1): Identity()\n",
       "              (dropout2): Identity()\n",
       "            )\n",
       "            (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (residual_norm_stage_0): ModuleList(\n",
       "      (0-3): 4 x LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (map_to_bev_module): PointPillarScatter3d()\n",
       "  (pfe): None\n",
       "  (backbone_2d): BaseBEVResBackbone(\n",
       "    (blocks): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU()\n",
       "          (downsample_layer): Sequential(\n",
       "            (0): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU()\n",
       "          (downsample_layer): Sequential(\n",
       "            (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU()\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU()\n",
       "          (downsample_layer): Sequential(\n",
       "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU()\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (deblocks): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): ConvTranspose2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(4, 4), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dense_head): CenterHead(\n",
       "    (shared_conv): Sequential(\n",
       "      (0): Conv2d(384, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (heads_list): ModuleList(\n",
       "      (0): SeparateHead(\n",
       "        (center): Sequential(\n",
       "          (0): Sequential(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (center_z): Sequential(\n",
       "          (0): Sequential(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (dim): Sequential(\n",
       "          (0): Sequential(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (iou): Sequential(\n",
       "          (0): Sequential(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (rot): Sequential(\n",
       "          (0): Sequential(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (hm): Sequential(\n",
       "          (0): Sequential(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (hm_loss_func): FocalLossCenterNet()\n",
       "    (reg_loss_func): RegLossCenterNet()\n",
       "  )\n",
       "  (point_head): None\n",
       "  (roi_head): None\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_network(model_cfg=cfg.MODEL, num_class=len(cfg.CLASS_NAMES), dataset=test_set)\n",
    "ckpt = \"./pillar/model.pth\"\n",
    "model.load_params_from_file(filename=ckpt, logger=logger, to_cpu=False, pre_trained_path=None)\n",
    "model.eval()\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bfa6d63-b83b-48b7-8214-57a532a1d31e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'points': tensor([[ 0.0000,  0.8040,  0.7984, -1.4852,  0.0000],\n",
       "         [ 0.0000,  0.8203,  0.7921, -1.4947,  0.0000],\n",
       "         [ 0.0000,  0.8500,  0.8309, -1.4720,  0.0000],\n",
       "         ...,\n",
       "         [ 0.0000, -0.6915,  0.6910,  1.2054,  0.0000],\n",
       "         [ 0.0000, -0.6724,  0.6628,  1.2318,  0.0000],\n",
       "         [ 0.0000, -0.6677,  0.6675,  1.2318,  0.0000]], device='cuda:0'),\n",
       " 'frame_id': array(['2024-03-09 04:57:20'], dtype='<U19'),\n",
       " 'lidar_aug_matrix': tensor([[[1., 0., 0., 0.],\n",
       "          [0., 1., 0., 0.],\n",
       "          [0., 0., 1., 0.],\n",
       "          [0., 0., 0., 1.]]], device='cuda:0'),\n",
       " 'use_lead_xyz': tensor([1.], device='cuda:0'),\n",
       " 'batch_size': 1}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_dict = torch.load(\"/mnt/nas2/users/eslim/onnx/sfaw/input_dict.pth\", map_location=\"cuda\")\n",
    "inputs = batch_dict\n",
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2162150-eb88-49c5-9954-605d225a53c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CenterPoint(\n",
       "  (vfe): DynamicVoxelVFE(\n",
       "    (pfn_layers): ModuleList(\n",
       "      (0): PFNLayerV2(\n",
       "        (linear): Linear(in_features=10, out_features=96, bias=False)\n",
       "        (norm): BatchNorm1d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): PFNLayerV2(\n",
       "        (linear): Linear(in_features=192, out_features=192, bias=False)\n",
       "        (norm): BatchNorm1d(192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (backbone_3d): DSVT(\n",
       "    (input_layer): DSVTInputLayer(\n",
       "      (posembed_layers): ModuleList(\n",
       "        (0): ModuleList(\n",
       "          (0-3): 4 x ModuleList(\n",
       "            (0-1): 2 x PositionEmbeddingLearned(\n",
       "              (position_embedding_head): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=192, bias=True)\n",
       "                (1): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU(inplace=True)\n",
       "                (3): Linear(in_features=192, out_features=192, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (stage_0): ModuleList(\n",
       "      (0-3): 4 x DSVTBlock(\n",
       "        (encoder_list): ModuleList(\n",
       "          (0-1): 2 x DSVT_EncoderLayer(\n",
       "            (win_attn): SetAttention(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
       "              )\n",
       "              (linear1): Linear(in_features=192, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0, inplace=False)\n",
       "              (linear2): Linear(in_features=384, out_features=192, bias=True)\n",
       "              (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout1): Identity()\n",
       "              (dropout2): Identity()\n",
       "            )\n",
       "            (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (residual_norm_stage_0): ModuleList(\n",
       "      (0-3): 4 x LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (map_to_bev_module): PointPillarScatter3d()\n",
       "  (pfe): None\n",
       "  (backbone_2d): BaseBEVResBackbone(\n",
       "    (blocks): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU()\n",
       "          (downsample_layer): Sequential(\n",
       "            (0): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU()\n",
       "          (downsample_layer): Sequential(\n",
       "            (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU()\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU()\n",
       "          (downsample_layer): Sequential(\n",
       "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU()\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (deblocks): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): ConvTranspose2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(4, 4), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dense_head): CenterHead(\n",
       "    (shared_conv): Sequential(\n",
       "      (0): Conv2d(384, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (heads_list): ModuleList(\n",
       "      (0): SeparateHead(\n",
       "        (center): Sequential(\n",
       "          (0): Sequential(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (center_z): Sequential(\n",
       "          (0): Sequential(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (dim): Sequential(\n",
       "          (0): Sequential(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (iou): Sequential(\n",
       "          (0): Sequential(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (rot): Sequential(\n",
       "          (0): Sequential(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (hm): Sequential(\n",
       "          (0): Sequential(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (hm_loss_func): FocalLossCenterNet()\n",
       "    (reg_loss_func): RegLossCenterNet()\n",
       "  )\n",
       "  (point_head): None\n",
       "  (roi_head): None\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33e7086c-da31-4865-8481-b239010fa98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.backbone_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f71c1817-416a-4baa-959d-76eaac88e21e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.3520, 0.7090, 0.6403,  ..., 0.6391, 0.5351, 0.9621],\n",
       "          [0.6059, 0.6821, 0.6289,  ..., 0.6430, 0.7770, 1.0879],\n",
       "          [0.4052, 0.5088, 0.1898,  ..., 0.1131, 0.3867, 0.8935],\n",
       "          ...,\n",
       "          [0.4514, 0.6178, 0.3753,  ..., 0.3189, 0.4214, 0.8849],\n",
       "          [0.5247, 0.6775, 0.6047,  ..., 0.6434, 0.6046, 0.9232],\n",
       "          [0.5045, 0.6075, 0.5154,  ..., 0.5288, 0.6361, 0.7326]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0208,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.0000, 0.1979, 0.2160,  ..., 0.0775, 0.1823, 0.2410],\n",
       "          [0.3319, 0.1860, 0.0934,  ..., 0.2182, 0.0971, 0.1500],\n",
       "          [0.1251, 0.0000, 0.1882,  ..., 0.0000, 0.3053, 0.0000],\n",
       "          ...,\n",
       "          [0.4010, 0.3580, 0.2028,  ..., 0.0391, 0.5095, 0.0000],\n",
       "          [0.0689, 0.0000, 0.0067,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.3874, 0.0000,  ..., 0.3753, 0.0000, 0.3984]],\n",
       "\n",
       "         [[0.8989, 0.0000, 0.3568,  ..., 0.0000, 0.3610, 0.1620],\n",
       "          [1.0730, 0.7344, 0.2638,  ..., 0.4773, 0.4265, 0.0000],\n",
       "          [0.5357, 0.1370, 0.2929,  ..., 0.0000, 0.2119, 0.8188],\n",
       "          ...,\n",
       "          [1.0300, 0.6118, 0.7511,  ..., 0.1708, 0.5602, 0.0000],\n",
       "          [0.9800, 0.7472, 0.3269,  ..., 0.0637, 0.2289, 1.0750],\n",
       "          [0.9412, 0.0376, 0.7666,  ..., 0.0265, 0.7341, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]],\n",
       "       device='cuda:0', grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_vfe = model.vfe(inputs)\n",
    "inputs_3d = model.backbone_3d(inputs_vfe)\n",
    "inputs_bev = model.map_to_bev_module(inputs_3d)\n",
    "inputs_2d = model.backbone_2d(inputs_bev)\n",
    "\n",
    "# inputs_bev\n",
    "inputs_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2296297-ebb6-4854-b09e-7adf38a815f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dict = {}\n",
    "input_dict = {}\n",
    "input_dict['data_dict']={}\n",
    "# input_dict['data_dict']['voxel_features'] = inputs_bev['voxel_features']\n",
    "# input_dict['data_dict']['use_lead_xyz'] = inputs_bev['use_lead_xyz']\n",
    "# input_dict['data_dict']['batch_size'] = torch.tensor(inputs_bev['batch_size'])\n",
    "# input_dict['data_dict']['pillar_features'] = inputs_bev['pillar_features']\n",
    "# input_dict['data_dict']['voxel_coords'] = inputs_bev['voxel_coords']\n",
    "input_dict['data_dict']['spatial_features'] = inputs_bev['spatial_features']\n",
    "\n",
    "\n",
    "# data_dict.update(inputs_bev)\n",
    "# data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddd08117-bed8-4c42-bea5-7d9e25518afd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseBEVResBackbone(\n",
       "  (blocks): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU()\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU()\n",
       "        (downsample_layer): Sequential(\n",
       "          (0): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU()\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU()\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU()\n",
       "        (downsample_layer): Sequential(\n",
       "          (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU()\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU()\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU()\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU()\n",
       "        (downsample_layer): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU()\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU()\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu1): ReLU()\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu2): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (deblocks): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): ConvTranspose2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(4, 4), bias=False)\n",
       "      (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DSVT_2d_Backbone = model.backbone_2d\n",
    "# DSVT_2d_Backbone\n",
    "model.backbone_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ebcfeeb-f598-40ed-93c2-c030832b9be4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    DSVT_2d_Backbone = model.backbone_2d\n",
    "    # dsvtblocks_list = DSVT_Backbone.stage_0\n",
    "    # layer_norms_list = DSVT_Backbone.residual_norm_stage_0\n",
    "    # inputs = model.vfe(inputs)\n",
    "    # voxel_info = DSVT_Backbone.input_layer(inputs)\n",
    "    # set_voxel_inds_list = [[voxel_info[f'set_voxel_inds_stage{s}_shift{i}'] for i in range(2)] for s in range(1)]\n",
    "    # set_voxel_masks_list = [[voxel_info[f'set_voxel_mask_stage{s}_shift{i}'] for i in range(2)] for s in range(1)]\n",
    "    # pos_embed_list = [[[voxel_info[f'pos_embed_stage{s}_block{b}_shift{i}'] for i in range(2)] for b in range(4)] for s in range(1)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b95eff5-cbae-409f-9b42-b3f498e4e172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_dict = {}\n",
    "# input_dict['batch_dict'] = {}\n",
    "# input_dict['batch_dict']['voxel_features'] = inputs['voxel_features']\n",
    "# input_dict['batch_dict']['voxel_coords']  = torch.tensor(inputs['voxel_coords'])\n",
    "input_names = [\n",
    "    # 'voxel_features',\n",
    "    # 'use_lead_xyz',\n",
    "    # 'batch_size',\n",
    "    # 'pillar_features',\n",
    "    # 'voxel_coords',\n",
    "    'spatial_features'\n",
    "]\n",
    "output_names = [\n",
    "    'output'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c02e25f-9ab5-4a0e-946b-1a112e8f3e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/dec/pcdet/models/backbones_2d/base_bev_backbone.py:334: TracerWarning: Converting a tensor to a Python integer might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  stride = int(spatial_features.shape[2] / x.shape[2])\n",
      "/usr/local/lib/python3.8/dist-packages/torch/onnx/utils.py:715: UserWarning: We detected that you are modifying a dictionary that is an input to your model. Note that dictionaries are allowed as inputs in ONNX but they should be handled with care. Usages of dictionaries is not recommended, and should not be used except for configuration use. Also note that the order and values of the keys must remain the same. \n",
      "  warnings.warn(warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base_name = \"./deploy_pillar_sfaw_2d_rev/dsvt_2d_bb\"\n",
    "ts_path = f\"{base_name}.ts\"\n",
    "onnx_path = f\"{base_name}.onnx\"\n",
    "\n",
    "# allptransblocktrt = AllDSVTBlocksTRT(dsvtblocks_list, layer_norms_list).eval().cuda()\n",
    "\n",
    "torch.onnx.export(\n",
    "    DSVT_2d_Backbone,\n",
    "    # alldsvtblockstrt_inputs,\n",
    "    input_dict,\n",
    "    onnx_path, \n",
    "    input_names=input_names,\n",
    "    output_names=output_names, \n",
    "    # dynamic_axes=dynamic_axes,\n",
    "    opset_version=14,\n",
    ")\n",
    "# https://github.com/Haiyang-W/DSVT/issues/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dcf6653b-c604-4643-be2a-1c4b9ab059d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# jit_mode = \"trace\"\n",
    "# input_names = [\n",
    "#     'src',\n",
    "#     'set_voxel_inds_tensor_shift_0',\n",
    "#     'set_voxel_inds_tensor_shift_1',\n",
    "#     'set_voxel_masks_tensor_shift_0',\n",
    "#     'set_voxel_masks_tensor_shift_1',\n",
    "#     'pos_embed_tensor'\n",
    "# ]\n",
    "# output_names = [\"output\",]\n",
    "# input_shapes = {\n",
    "#     \"src\": {\n",
    "#         \"min_shape\": [24629, 192],\n",
    "#         \"opt_shape\": [24629, 192],\n",
    "#         \"max_shape\": [24629, 192],\n",
    "#     },\n",
    "#     \"set_voxel_inds_tensor_shift_0\": {\n",
    "#         \"min_shape\": [2, 1156, 36],\n",
    "#         \"opt_shape\": [2, 1156, 36],\n",
    "#         \"max_shape\": [2, 1156, 36],\n",
    "#     },\n",
    "#     \"set_voxel_inds_tensor_shift_1\": {\n",
    "#         \"min_shape\": [2, 834, 36],\n",
    "#         \"opt_shape\": [2, 834, 36],\n",
    "#         \"max_shape\": [2, 834, 36],\n",
    "#     },\n",
    "#     \"set_voxel_masks_tensor_shift_0\": {\n",
    "#         \"min_shape\": [2, 1156, 36],\n",
    "#         \"opt_shape\": [2, 1156, 36],\n",
    "#         \"max_shape\": [2, 1156, 36],\n",
    "#     },\n",
    "#     \"set_voxel_masks_tensor_shift_1\": {\n",
    "#         \"min_shape\": [2, 834, 36],\n",
    "#         \"opt_shape\": [2, 834, 36],\n",
    "#         \"max_shape\": [2, 834, 36],\n",
    "#     },\n",
    "#     \"pos_embed_tensor\": {\n",
    "#         \"min_shape\": [4, 2, 24629, 192],\n",
    "#         \"opt_shape\": [4, 2, 24629, 192],\n",
    "#         \"max_shape\": [4, 2, 24629, 192],\n",
    "#     },\n",
    "# }\n",
    "\n",
    "# dynamic_axes = {\n",
    "#     \"src\": {\n",
    "#         0: \"voxel_number\",\n",
    "#     },\n",
    "#     \"set_voxel_inds_tensor_shift_0\": {\n",
    "#         1: \"set_number_shift_0\",\n",
    "#     },\n",
    "#     \"set_voxel_inds_tensor_shift_1\": {\n",
    "#         1: \"set_number_shift_1\",\n",
    "#     },\n",
    "#     \"set_voxel_masks_tensor_shift_0\": {\n",
    "#         1: \"set_number_shift_0\",\n",
    "#     },\n",
    "#     \"set_voxel_masks_tensor_shift_1\": {\n",
    "#         1: \"set_number_shift_1\",\n",
    "#     },\n",
    "#     \"pos_embed_tensor\": {\n",
    "#         2: \"voxel_number\",\n",
    "#     },\n",
    "#     \"output\": {\n",
    "#         0: \"voxel_number\",\n",
    "#     }\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cff39cd7-ffb4-4dee-b3e0-82264ebd87ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# to_numpy(input_dict['data_dict']['voxel_features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94806e45-a969-4b21-93f2-79143b2911d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test onnx\n",
    "ort_session = ort.InferenceSession(onnx_path)\n",
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "\n",
    "# compute ONNX Runtime output prediction\n",
    "# ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(pillar_features),\n",
    "#               ort_session.get_inputs()[1].name: to_numpy(set_voxel_inds_list[0][0]),\n",
    "#               ort_session.get_inputs()[2].name: to_numpy(set_voxel_inds_list[0][1]),\n",
    "#               ort_session.get_inputs()[3].name: to_numpy(set_voxel_masks_list[0][0]),\n",
    "#               ort_session.get_inputs()[4].name: to_numpy(set_voxel_masks_list[0][1]),\n",
    "#               ort_session.get_inputs()[5].name: to_numpy(torch.stack([torch.stack(v, dim=0) for v in pos_embed_list[0]], dim=0)),}\n",
    "# input_names = [\n",
    "#     'voxel_features',\n",
    "#     'use_lead_xyz',\n",
    "#     'batch_size',\n",
    "#     'pillar_features',\n",
    "#     'voxel_coords',\n",
    "#     'spatial_features'\n",
    "# ]\n",
    "ort_inputs = {\n",
    "    # 'voxel_features' : to_numpy(input_dict['data_dict']['voxel_features']),\n",
    "    # 'use_lead_xyz' : to_numpy(input_dict['data_dict']['use_lead_xyz']),\n",
    "    # 'batch_size' :  np.array(1, dtype=np.int64),\n",
    "    # 'pillar_features' : to_numpy(input_dict['data_dict']['pillar_features']),\n",
    "    # 'voxel_coords' : to_numpy(input_dict['data_dict']['voxel_coords']),\n",
    "    'spatial_features' : to_numpy(input_dict['data_dict']['spatial_features'])\n",
    "}\n",
    "# = input_dict\n",
    "ort_outs = ort_session.run(None, ort_inputs)\n",
    "# ort_outs[0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "104d0b46-3a98-4089-a875-bff978865329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[[[0.35196745, 0.70897365, 0.6402973 , ..., 0.639117  ,\n",
       "           0.5351288 , 0.9620945 ],\n",
       "          [0.6058658 , 0.68209326, 0.6289264 , ..., 0.6429725 ,\n",
       "           0.7770473 , 1.08794   ],\n",
       "          [0.4051624 , 0.50884706, 0.18977597, ..., 0.11309573,\n",
       "           0.38667515, 0.8934765 ],\n",
       "          ...,\n",
       "          [0.45144504, 0.6177946 , 0.37533143, ..., 0.31885695,\n",
       "           0.42140126, 0.88487935],\n",
       "          [0.52471024, 0.6774818 , 0.6046761 , ..., 0.64335114,\n",
       "           0.6045774 , 0.9232498 ],\n",
       "          [0.5045047 , 0.6074514 , 0.51535493, ..., 0.52884215,\n",
       "           0.6361034 , 0.73259795]],\n",
       " \n",
       "         [[0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.0208385 , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ]],\n",
       " \n",
       "         [[0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.        , 0.19795007, 0.21601531, ..., 0.07748826,\n",
       "           0.18229073, 0.24095818],\n",
       "          [0.331886  , 0.18602535, 0.09338261, ..., 0.2182024 ,\n",
       "           0.09710005, 0.15000391],\n",
       "          [0.12506366, 0.        , 0.18820335, ..., 0.        ,\n",
       "           0.30530006, 0.        ],\n",
       "          ...,\n",
       "          [0.40101153, 0.35803324, 0.20281366, ..., 0.03908257,\n",
       "           0.5095211 , 0.        ],\n",
       "          [0.06889779, 0.        , 0.00673862, ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.387425  , 0.        , ..., 0.37526515,\n",
       "           0.        , 0.39843017]],\n",
       " \n",
       "         [[0.89891183, 0.        , 0.35684308, ..., 0.        ,\n",
       "           0.36096752, 0.16201466],\n",
       "          [1.07297   , 0.7343879 , 0.2637777 , ..., 0.47726223,\n",
       "           0.42647058, 0.        ],\n",
       "          [0.5356904 , 0.13697018, 0.29292998, ..., 0.        ,\n",
       "           0.21192952, 0.81882393],\n",
       "          ...,\n",
       "          [1.0300378 , 0.61176544, 0.751088  , ..., 0.17077652,\n",
       "           0.56019866, 0.        ],\n",
       "          [0.98000336, 0.74723315, 0.32686982, ..., 0.06370046,\n",
       "           0.2288964 , 1.0750434 ],\n",
       "          [0.94121575, 0.03760587, 0.7665682 , ..., 0.02645935,\n",
       "           0.734095  , 0.        ]],\n",
       " \n",
       "         [[0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          ...,\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ],\n",
       "          [0.        , 0.        , 0.        , ..., 0.        ,\n",
       "           0.        , 0.        ]]]], dtype=float32)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ort_outs\n",
    "#spatial_features_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0fb8cc-6cfc-4525-805d-096639d39c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "\n",
    "\n",
    "# class BaseBEVBackbone(nn.Module):\n",
    "#     def __init__(self, model_cfg, input_channels):\n",
    "#         super().__init__()\n",
    "#         self.model_cfg = model_cfg\n",
    "\n",
    "#         if self.model_cfg.get('LAYER_NUMS', None) is not None:\n",
    "#             assert len(self.model_cfg.LAYER_NUMS) == len(self.model_cfg.LAYER_STRIDES) == len(self.model_cfg.NUM_FILTERS)\n",
    "#             layer_nums = self.model_cfg.LAYER_NUMS\n",
    "#             layer_strides = self.model_cfg.LAYER_STRIDES\n",
    "#             num_filters = self.model_cfg.NUM_FILTERS\n",
    "#         else:\n",
    "#             layer_nums = layer_strides = num_filters = []\n",
    "\n",
    "#         if self.model_cfg.get('UPSAMPLE_STRIDES', None) is not None:\n",
    "#             assert len(self.model_cfg.UPSAMPLE_STRIDES) == len(self.model_cfg.NUM_UPSAMPLE_FILTERS)\n",
    "#             num_upsample_filters = self.model_cfg.NUM_UPSAMPLE_FILTERS\n",
    "#             upsample_strides = self.model_cfg.UPSAMPLE_STRIDES\n",
    "#         else:\n",
    "#             upsample_strides = num_upsample_filters = []\n",
    "\n",
    "#         num_levels = len(layer_nums)\n",
    "#         c_in_list = [input_channels, *num_filters[:-1]]\n",
    "#         self.blocks = nn.ModuleList()\n",
    "#         self.deblocks = nn.ModuleList()\n",
    "#         for idx in range(num_levels):\n",
    "#             cur_layers = [\n",
    "#                 nn.ZeroPad2d(1),\n",
    "#                 nn.Conv2d(\n",
    "#                     c_in_list[idx], num_filters[idx], kernel_size=3,\n",
    "#                     stride=layer_strides[idx], padding=0, bias=False\n",
    "#                 ),\n",
    "#                 nn.BatchNorm2d(num_filters[idx], eps=1e-3, momentum=0.01),\n",
    "#                 nn.ReLU()\n",
    "#             ]\n",
    "#             for k in range(layer_nums[idx]):\n",
    "#                 cur_layers.extend([\n",
    "#                     nn.Conv2d(num_filters[idx], num_filters[idx], kernel_size=3, padding=1, bias=False),\n",
    "#                     nn.BatchNorm2d(num_filters[idx], eps=1e-3, momentum=0.01),\n",
    "#                     nn.ReLU()\n",
    "#                 ])\n",
    "#             self.blocks.append(nn.Sequential(*cur_layers))\n",
    "#             if len(upsample_strides) > 0:\n",
    "#                 stride = upsample_strides[idx]\n",
    "#                 if stride > 1 or (stride == 1 and not self.model_cfg.get('USE_CONV_FOR_NO_STRIDE', False)):\n",
    "#                     self.deblocks.append(nn.Sequential(\n",
    "#                         nn.ConvTranspose2d(\n",
    "#                             num_filters[idx], num_upsample_filters[idx],\n",
    "#                             upsample_strides[idx],\n",
    "#                             stride=upsample_strides[idx], bias=False\n",
    "#                         ),\n",
    "#                         nn.BatchNorm2d(num_upsample_filters[idx], eps=1e-3, momentum=0.01),\n",
    "#                         nn.ReLU()\n",
    "#                     ))\n",
    "#                 else:\n",
    "#                     stride = np.round(1 / stride).astype(np.int)\n",
    "#                     self.deblocks.append(nn.Sequential(\n",
    "#                         nn.Conv2d(\n",
    "#                             num_filters[idx], num_upsample_filters[idx],\n",
    "#                             stride,\n",
    "#                             stride=stride, bias=False\n",
    "#                         ),\n",
    "#                         nn.BatchNorm2d(num_upsample_filters[idx], eps=1e-3, momentum=0.01),\n",
    "#                         nn.ReLU()\n",
    "#                     ))\n",
    "\n",
    "#         c_in = sum(num_upsample_filters)\n",
    "#         if len(upsample_strides) > num_levels:\n",
    "#             self.deblocks.append(nn.Sequential(\n",
    "#                 nn.ConvTranspose2d(c_in, c_in, upsample_strides[-1], stride=upsample_strides[-1], bias=False),\n",
    "#                 nn.BatchNorm2d(c_in, eps=1e-3, momentum=0.01),\n",
    "#                 nn.ReLU(),\n",
    "#             ))\n",
    "\n",
    "#         self.num_bev_features = c_in\n",
    "\n",
    "#     def forward(self, data_dict):\n",
    "#         \"\"\"\n",
    "#         Args:\n",
    "#             data_dict:\n",
    "#                 spatial_features\n",
    "#         Returns:\n",
    "#         \"\"\"\n",
    "#         spatial_features = data_dict['spatial_features']\n",
    "#         ups = []\n",
    "#         ret_dict = {}\n",
    "#         x = spatial_features\n",
    "#         for i in range(len(self.blocks)):\n",
    "#             x = self.blocks[i](x)\n",
    "\n",
    "#             stride = int(spatial_features.shape[2] / x.shape[2])\n",
    "#             ret_dict['spatial_features_%dx' % stride] = x\n",
    "#             if len(self.deblocks) > 0:\n",
    "#                 ups.append(self.deblocks[i](x))\n",
    "#             else:\n",
    "#                 ups.append(x)\n",
    "\n",
    "#         if len(ups) > 1:\n",
    "#             x = torch.cat(ups, dim=1)\n",
    "#         elif len(ups) == 1:\n",
    "#             x = ups[0]\n",
    "\n",
    "#         if len(self.deblocks) > len(self.blocks):\n",
    "#             x = self.deblocks[-1](x)\n",
    "\n",
    "#         data_dict['spatial_features_2d'] = x\n",
    "\n",
    "#         return data_dict\n",
    "\n",
    "\n",
    "# class BaseBEVBackboneV1(nn.Module):\n",
    "#     def __init__(self, model_cfg, **kwargs):\n",
    "#         super().__init__()\n",
    "#         self.model_cfg = model_cfg\n",
    "\n",
    "#         layer_nums = self.model_cfg.LAYER_NUMS\n",
    "#         num_filters = self.model_cfg.NUM_FILTERS\n",
    "#         assert len(layer_nums) == len(num_filters) == 2\n",
    "\n",
    "#         num_upsample_filters = self.model_cfg.NUM_UPSAMPLE_FILTERS\n",
    "#         upsample_strides = self.model_cfg.UPSAMPLE_STRIDES\n",
    "#         assert len(num_upsample_filters) == len(upsample_strides)\n",
    "\n",
    "#         num_levels = len(layer_nums)\n",
    "#         self.blocks = nn.ModuleList()\n",
    "#         self.deblocks = nn.ModuleList()\n",
    "#         for idx in range(num_levels):\n",
    "#             cur_layers = [\n",
    "#                 nn.ZeroPad2d(1),\n",
    "#                 nn.Conv2d(\n",
    "#                     num_filters[idx], num_filters[idx], kernel_size=3,\n",
    "#                     stride=1, padding=0, bias=False\n",
    "#                 ),\n",
    "#                 nn.BatchNorm2d(num_filters[idx], eps=1e-3, momentum=0.01),\n",
    "#                 nn.ReLU()\n",
    "#             ]\n",
    "#             for k in range(layer_nums[idx]):\n",
    "#                 cur_layers.extend([\n",
    "#                     nn.Conv2d(num_filters[idx], num_filters[idx], kernel_size=3, padding=1, bias=False),\n",
    "#                     nn.BatchNorm2d(num_filters[idx], eps=1e-3, momentum=0.01),\n",
    "#                     nn.ReLU()\n",
    "#                 ])\n",
    "#             self.blocks.append(nn.Sequential(*cur_layers))\n",
    "#             if len(upsample_strides) > 0:\n",
    "#                 stride = upsample_strides[idx]\n",
    "#                 if stride >= 1:\n",
    "#                     self.deblocks.append(nn.Sequential(\n",
    "#                         nn.ConvTranspose2d(\n",
    "#                             num_filters[idx], num_upsample_filters[idx],\n",
    "#                             upsample_strides[idx],\n",
    "#                             stride=upsample_strides[idx], bias=False\n",
    "#                         ),\n",
    "#                         nn.BatchNorm2d(num_upsample_filters[idx], eps=1e-3, momentum=0.01),\n",
    "#                         nn.ReLU()\n",
    "#                     ))\n",
    "#                 else:\n",
    "#                     stride = np.round(1 / stride).astype(np.int)\n",
    "#                     self.deblocks.append(nn.Sequential(\n",
    "#                         nn.Conv2d(\n",
    "#                             num_filters[idx], num_upsample_filters[idx],\n",
    "#                             stride,\n",
    "#                             stride=stride, bias=False\n",
    "#                         ),\n",
    "#                         nn.BatchNorm2d(num_upsample_filters[idx], eps=1e-3, momentum=0.01),\n",
    "#                         nn.ReLU()\n",
    "#                     ))\n",
    "\n",
    "#         c_in = sum(num_upsample_filters)\n",
    "#         if len(upsample_strides) > num_levels:\n",
    "#             self.deblocks.append(nn.Sequential(\n",
    "#                 nn.ConvTranspose2d(c_in, c_in, upsample_strides[-1], stride=upsample_strides[-1], bias=False),\n",
    "#                 nn.BatchNorm2d(c_in, eps=1e-3, momentum=0.01),\n",
    "#                 nn.ReLU(),\n",
    "#             ))\n",
    "\n",
    "#         self.num_bev_features = c_in\n",
    "\n",
    "#     def forward(self, data_dict):\n",
    "#         \"\"\"\n",
    "#         Args:\n",
    "#             data_dict:\n",
    "#                 spatial_features\n",
    "#         Returns:\n",
    "#         \"\"\"\n",
    "#         spatial_features = data_dict['multi_scale_2d_features']\n",
    "\n",
    "#         x_conv4 = spatial_features['x_conv4']\n",
    "#         x_conv5 = spatial_features['x_conv5']\n",
    "\n",
    "#         ups = [self.deblocks[0](x_conv4)]\n",
    "\n",
    "#         x = self.blocks[1](x_conv5)\n",
    "#         ups.append(self.deblocks[1](x))\n",
    "\n",
    "#         x = torch.cat(ups, dim=1)\n",
    "#         x = self.blocks[0](x)\n",
    "\n",
    "#         data_dict['spatial_features_2d'] = x\n",
    "\n",
    "#         return data_dict\n",
    "\n",
    "\n",
    "# class BasicBlock(nn.Module):\n",
    "#     expansion: int = 1\n",
    "\n",
    "#     def __init__(\n",
    "#         self,\n",
    "#         inplanes: int,\n",
    "#         planes: int,\n",
    "#         stride: int = 1,\n",
    "#         padding: int = 1,\n",
    "#         downsample: bool = False,\n",
    "#     ) -> None:\n",
    "#         super().__init__()\n",
    "#         self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=3, stride=stride, padding=padding, bias=False)\n",
    "#         self.bn1 = nn.BatchNorm2d(planes, eps=1e-3, momentum=0.01)\n",
    "#         self.relu1 = nn.ReLU()\n",
    "#         self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, padding=1, bias=False)\n",
    "#         self.bn2 = nn.BatchNorm2d(planes, eps=1e-3, momentum=0.01)\n",
    "#         self.relu2 = nn.ReLU()\n",
    "#         self.downsample = downsample\n",
    "#         if self.downsample:\n",
    "#             self.downsample_layer = nn.Sequential(\n",
    "#                 nn.Conv2d(inplanes, planes, kernel_size=1, stride=stride, padding=0, bias=False),\n",
    "#                 nn.BatchNorm2d(planes, eps=1e-3, momentum=0.01)\n",
    "#             )\n",
    "#         self.stride = stride\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         identity = x\n",
    "\n",
    "#         out = self.conv1(x)\n",
    "#         out = self.bn1(out)\n",
    "#         out = self.relu1(out)\n",
    "\n",
    "#         out = self.conv2(out)\n",
    "#         out = self.bn2(out)\n",
    "\n",
    "#         if self.downsample:\n",
    "#             identity = self.downsample_layer(x)\n",
    "\n",
    "#         out += identity\n",
    "#         out = self.relu2(out)\n",
    "\n",
    "#         return out\n",
    "\n",
    "\n",
    "# class BaseBEVResBackbone(nn.Module):\n",
    "#     def __init__(self, model_cfg, input_channels):\n",
    "#         super().__init__()\n",
    "#         self.model_cfg = model_cfg\n",
    "\n",
    "#         if self.model_cfg.get('LAYER_NUMS', None) is not None:\n",
    "#             assert len(self.model_cfg.LAYER_NUMS) == len(self.model_cfg.LAYER_STRIDES) == len(self.model_cfg.NUM_FILTERS)\n",
    "#             layer_nums = self.model_cfg.LAYER_NUMS\n",
    "#             layer_strides = self.model_cfg.LAYER_STRIDES\n",
    "#             num_filters = self.model_cfg.NUM_FILTERS\n",
    "#         else:\n",
    "#             layer_nums = layer_strides = num_filters = []\n",
    "\n",
    "#         if self.model_cfg.get('UPSAMPLE_STRIDES', None) is not None:\n",
    "#             assert len(self.model_cfg.UPSAMPLE_STRIDES) == len(self.model_cfg.NUM_UPSAMPLE_FILTERS)\n",
    "#             num_upsample_filters = self.model_cfg.NUM_UPSAMPLE_FILTERS\n",
    "#             upsample_strides = self.model_cfg.UPSAMPLE_STRIDES\n",
    "#         else:\n",
    "#             upsample_strides = num_upsample_filters = []\n",
    "\n",
    "#         num_levels = len(layer_nums)\n",
    "#         c_in_list = [input_channels, *num_filters[:-1]]\n",
    "#         self.blocks = nn.ModuleList()\n",
    "#         self.deblocks = nn.ModuleList()\n",
    "#         for idx in range(num_levels):\n",
    "#             cur_layers = [\n",
    "#                 # nn.ZeroPad2d(1),\n",
    "#                 BasicBlock(c_in_list[idx], num_filters[idx], layer_strides[idx], 1, True)\n",
    "#             ]\n",
    "#             for k in range(layer_nums[idx]):\n",
    "#                 cur_layers.extend([\n",
    "#                     BasicBlock(num_filters[idx], num_filters[idx])\n",
    "#                 ])\n",
    "#             self.blocks.append(nn.Sequential(*cur_layers))\n",
    "#             if len(upsample_strides) > 0:\n",
    "#                 stride = upsample_strides[idx]\n",
    "#                 if stride >= 1:\n",
    "#                     self.deblocks.append(nn.Sequential(\n",
    "#                         nn.ConvTranspose2d(\n",
    "#                             num_filters[idx], num_upsample_filters[idx],\n",
    "#                             upsample_strides[idx],\n",
    "#                             stride=upsample_strides[idx], bias=False\n",
    "#                         ),\n",
    "#                         nn.BatchNorm2d(num_upsample_filters[idx], eps=1e-3, momentum=0.01),\n",
    "#                         nn.ReLU()\n",
    "#                     ))\n",
    "#                 else:\n",
    "#                     stride = np.round(1 / stride).astype(np.int)\n",
    "#                     self.deblocks.append(nn.Sequential(\n",
    "#                         nn.Conv2d(\n",
    "#                             num_filters[idx], num_upsample_filters[idx],\n",
    "#                             stride,\n",
    "#                             stride=stride, bias=False\n",
    "#                         ),\n",
    "#                         nn.BatchNorm2d(num_upsample_filters[idx], eps=1e-3, momentum=0.01),\n",
    "#                         nn.ReLU()\n",
    "#                     ))\n",
    "\n",
    "#         c_in = sum(num_upsample_filters) if len(num_upsample_filters) > 0 else sum(num_filters)\n",
    "#         if len(upsample_strides) > num_levels:\n",
    "#             self.deblocks.append(nn.Sequential(\n",
    "#                 nn.ConvTranspose2d(c_in, c_in, upsample_strides[-1], stride=upsample_strides[-1], bias=False),\n",
    "#                 nn.BatchNorm2d(c_in, eps=1e-3, momentum=0.01),\n",
    "#                 nn.ReLU(),\n",
    "#             ))\n",
    "\n",
    "#         self.num_bev_features = c_in\n",
    "\n",
    "#     def forward(self, data_dict):\n",
    "#         \"\"\"\n",
    "#         Args:\n",
    "#             data_dict:\n",
    "#                 spatial_features\n",
    "#         Returns:\n",
    "#         \"\"\"\n",
    "#         spatial_features = data_dict['spatial_features']\n",
    "#         ups = []\n",
    "#         ret_dict = {}\n",
    "#         x = spatial_features\n",
    "#         for i in range(len(self.blocks)):\n",
    "#             x = self.blocks[i](x)\n",
    "\n",
    "#             stride = int(spatial_features.shape[2] / x.shape[2])\n",
    "#             ret_dict['spatial_features_%dx' % stride] = x\n",
    "#             if len(self.deblocks) > 0:\n",
    "#                 ups.append(self.deblocks[i](x))\n",
    "#             else:\n",
    "#                 ups.append(x)\n",
    "\n",
    "#         if len(ups) > 1:\n",
    "#             x = torch.cat(ups, dim=1)\n",
    "#         elif len(ups) == 1:\n",
    "#             x = ups[0]\n",
    "\n",
    "#         if len(self.deblocks) > len(self.blocks):\n",
    "#             x = self.deblocks[-1](x)\n",
    "\n",
    "#         data_dict['spatial_features_2d'] = x\n",
    "#         # print(\"check\")\n",
    "#         # return x\n",
    "#         return data_dict\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
