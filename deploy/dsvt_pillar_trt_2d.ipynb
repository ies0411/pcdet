{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5367841a-db44-47da-ac41-923c5f82f4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "# 코드에서 nms제외해야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9aa41efc-82ea-4e45-bd9b-7f910a81df94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python3 -m pip install --pre-upgrade tensorrt\n",
    "# !pip install pycuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b385e2e-4ab7-4f1e-a7d3-9799101350f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "875dbfda-d810-428b-a6c3-48eddb22a569",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python3 -m pip install --pre --upgrade tensorrt\n",
    "# !apt-get install tensorrt -y\n",
    "# !wget https://developer.nvidia.com/downloads/compute/machine-learning/tensorrt/10.0.0/tars/TensorRT-10.0.0.6.Linux.x86_64-gnu.cuda-11.8.tar.gz\n",
    "\n",
    "# python3 -m pip install tensorrt-10.0.0b6-cp38-none-linux_x86_64.whl\n",
    "# export PATH=/path/to/tensorrt/bin:$PATH\n",
    "# export LD_LIBRARY_PATH=<TensorRT-${version}/lib>:$LD_LIBRARY_PATH\n",
    "# source ~/.bashrc\n",
    "# https://docs.nvidia.com/deeplearning/tensorrt/install-guide/index.html#installing-tar\n",
    "# https://da2so.tistory.com/61"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c47c2a81-7429-437b-98fe-b70754366732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_name = \"./deploy_pillar_sfaw_3d/dsvt_3d_bb.onnx\"\n",
    "# --memPoolSize=workspace:4096\n",
    "# --device=1\n",
    "# --buildOnly\n",
    "# --tacticSources=+CUDNN,+CUBLAS,-CUBLAS_LT,+EDGE_MASK_CONVOLUTIONS \\\n",
    "# --minShapes=src:3000x192,set_voxel_inds_tensor_shift_0:2x170x36,set_voxel_inds_tensor_shift_1:2x100x36,set_voxel_masks_tensor_shift_0:2x170x36,set_voxel_masks_tensor_shift_1:2x100x36,pos_embed_tensor:4x2x3000x192 \\\n",
    "# --optShapes=src:20000x192,set_voxel_inds_tensor_shift_0:2x1000x36,set_voxel_inds_tensor_shift_1:2x700x36,set_voxel_masks_tensor_shift_0:2x1000x36,set_voxel_masks_tensor_shift_1:2x700x36,pos_embed_tensor:4x2x20000x192 \\\n",
    "# --maxShapes=src:35000x192,set_voxel_inds_tensor_shift_0:2x1500x36,set_voxel_inds_tensor_shift_1:2x1200x36,set_voxel_masks_tensor_shift_0:2x1500x36,set_voxel_masks_tensor_shift_1:2x1200x36,pos_embed_tensor:4x2x35000x192 \n",
    "\n",
    "\n",
    "# !trtexec --onnx=./deploy_pillar_sfaw_3d_origin/deploy_pillar_sfaw_3d_origin.onnx  --saveEngine=./deploy_pillar_sfaw_3d/dsvt_3d_bb_origin.engine --verbose   --fp16\n",
    "\n",
    "# --optShapes=src:962x192,set_voxel_inds_tensor_shift_0:2x40x36,set_voxel_inds_tensor_shift_1:2x34x36,set_voxel_masks_tensor_shift_0:2x40x36,set_voxel_masks_tensor_shift_1:2x34x36,pos_embed_tensor:4x2x962x192 \\\n",
    "# --optShapes=src:20000x192,set_voxel_inds_tensor_shift_0:2x1000x36,set_voxel_inds_tensor_shift_1:2x700x36,set_voxel_masks_tensor_shift_0:2x1000x36,set_voxel_masks_tensor_shift_1:2x700x36,pos_embed_tensor:4x2x20000x192 \\\n",
    "# --maxShapes=src:35000x192,set_voxel_inds_tensor_shift_0:2x1500x36,set_voxel_inds_tensor_shift_1:2x1200x36,set_voxel_masks_tensor_shift_0:2x1500x36,set_voxel_masks_tensor_shift_1:2x1200x36,pos_embed_tensor:4x2x35000x192 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "770ea0b4-0a87-4f8b-8366-6f1641d1fc73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: detected dubious ownership in repository at '/mnt/nas2/users/eslim/workspace/OpenPCDet'\n",
      "To add an exception for this directory, call:\n",
      "\n",
      "\tgit config --global --add safe.directory /mnt/nas2/users/eslim/workspace/OpenPCDet\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorrt as trt\n",
    "import torch\n",
    "from pcdet.config import cfg, cfg_from_yaml_file\n",
    "from pcdet.models import build_network\n",
    "from pcdet.datasets import build_dataloader\n",
    "from pcdet.utils import common_utils\n",
    "# import pycuda.driver as cuda\n",
    "# import pycuda.autoinit\n",
    "# import torch_tensorrt\n",
    "\n",
    "# import pycuda.driver as cuda\n",
    "# import pycuda.autoinit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea8aedf6-2698-4a84-9dc6-0f914e4c1e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-19 01:52:35,061   INFO  Loading Custom dataset.\n",
      "2024-04-19 01:52:35,063   INFO  Total samples for CUSTOM dataset: 0\n",
      "2024-04-19 01:52:37,319   INFO  ==> Loading parameters from checkpoint ./pillar/model.pth to GPU\n",
      "2024-04-19 01:52:37,470   INFO  ==> Checkpoint trained from version: pcdet+0.6.0+255db8f\n",
      "2024-04-19 01:52:37,514   INFO  ==> Done (loaded 391/391)\n"
     ]
    }
   ],
   "source": [
    "####### load model #######\n",
    "# cfg_file = \"./cfgs/dsvt_models/dsvt_plain_1f_onestage.yaml\"\n",
    "# cfg_from_yaml_file(cfg_file, cfg)\n",
    "# if os.path.exists('./deploy_files')==False:\n",
    "#     os.mkdir('./deploy_files')\n",
    "# log_file = './deploy_files/log_trt.log'\n",
    "\n",
    "cfg_file = \"./pillar/config.yaml\"\n",
    "cfg_from_yaml_file(cfg_file, cfg)\n",
    "if os.path.exists('./deploy_pillar_sfaw_2d_rev')==False:\n",
    "    os.mkdir('./deploy_pillar_sfaw_2d_rev')\n",
    "log_file = './deploy_pillar_sfaw_2d_rev/log_trt.log'\n",
    "\n",
    "logger = common_utils.create_logger(log_file, rank=0)\n",
    "test_set, test_loader, sampler = build_dataloader(\n",
    "    dataset_cfg=cfg.DATA_CONFIG,\n",
    "    class_names=cfg.CLASS_NAMES,\n",
    "    batch_size=1,\n",
    "    dist=False, workers=8, logger=logger, training=False\n",
    ")\n",
    "\n",
    "model = build_network(model_cfg=cfg.MODEL, num_class=len(cfg.CLASS_NAMES), dataset=test_set)\n",
    "ckpt = \"./pillar/model.pth\"\n",
    "\n",
    "model.load_params_from_file(filename=ckpt, logger=logger, to_cpu=False, pre_trained_path=None)\n",
    "model.eval()\n",
    "model.cuda()\n",
    "####### load model #######\n",
    "\n",
    "####### read input #######\n",
    "batch_dict = torch.load(\"/mnt/nas2/users/eslim/onnx/sfaw/input_dict.pth\", map_location=\"cuda\")\n",
    "inputs = batch_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26025b6f-78fc-42d4-9492-aea54475d2e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CenterPoint(\n",
       "  (vfe): DynamicVoxelVFE(\n",
       "    (pfn_layers): ModuleList(\n",
       "      (0): PFNLayerV2(\n",
       "        (linear): Linear(in_features=10, out_features=96, bias=False)\n",
       "        (norm): BatchNorm1d(96, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (1): PFNLayerV2(\n",
       "        (linear): Linear(in_features=192, out_features=192, bias=False)\n",
       "        (norm): BatchNorm1d(192, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (backbone_3d): DSVT(\n",
       "    (input_layer): DSVTInputLayer(\n",
       "      (posembed_layers): ModuleList(\n",
       "        (0): ModuleList(\n",
       "          (0-3): 4 x ModuleList(\n",
       "            (0-1): 2 x PositionEmbeddingLearned(\n",
       "              (position_embedding_head): Sequential(\n",
       "                (0): Linear(in_features=2, out_features=192, bias=True)\n",
       "                (1): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (2): ReLU(inplace=True)\n",
       "                (3): Linear(in_features=192, out_features=192, bias=True)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (stage_0): ModuleList(\n",
       "      (0-3): 4 x DSVTBlock(\n",
       "        (encoder_list): ModuleList(\n",
       "          (0-1): 2 x DSVT_EncoderLayer(\n",
       "            (win_attn): SetAttention(\n",
       "              (self_attn): MultiheadAttention(\n",
       "                (out_proj): NonDynamicallyQuantizableLinear(in_features=192, out_features=192, bias=True)\n",
       "              )\n",
       "              (linear1): Linear(in_features=192, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0, inplace=False)\n",
       "              (linear2): Linear(in_features=384, out_features=192, bias=True)\n",
       "              (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout1): Identity()\n",
       "              (dropout2): Identity()\n",
       "            )\n",
       "            (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (residual_norm_stage_0): ModuleList(\n",
       "      (0-3): 4 x LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (map_to_bev_module): PointPillarScatter3d()\n",
       "  (pfe): None\n",
       "  (backbone_2d): BaseBEVResBackbone(\n",
       "    (blocks): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU()\n",
       "          (downsample_layer): Sequential(\n",
       "            (0): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU()\n",
       "          (downsample_layer): Sequential(\n",
       "            (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU()\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU()\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU()\n",
       "        )\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU()\n",
       "          (downsample_layer): Sequential(\n",
       "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU()\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu1): ReLU()\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu2): ReLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (deblocks): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): ConvTranspose2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(4, 4), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dense_head): CenterHead(\n",
       "    (shared_conv): Sequential(\n",
       "      (0): Conv2d(384, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (heads_list): ModuleList(\n",
       "      (0): SeparateHead(\n",
       "        (center): Sequential(\n",
       "          (0): Sequential(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (center_z): Sequential(\n",
       "          (0): Sequential(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (dim): Sequential(\n",
       "          (0): Sequential(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (iou): Sequential(\n",
       "          (0): Sequential(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (rot): Sequential(\n",
       "          (0): Sequential(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): Conv2d(64, 2, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (hm): Sequential(\n",
       "          (0): Sequential(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU()\n",
       "          )\n",
       "          (1): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (hm_loss_func): FocalLossCenterNet()\n",
       "    (reg_loss_func): RegLossCenterNet()\n",
       "  )\n",
       "  (point_head): None\n",
       "  (roi_head): None\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eae43dfd-a927-4233-bff6-03eebc5048d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory Allocated: 0.24 GB\n",
      "Memory Allocated: 0.36 GB\n",
      "Memory Allocated: 0.52 GB\n",
      "Memory Allocated: 2.91 GB\n",
      "1.080721139907837\n",
      "Memory Allocated: 2.91 GB\n",
      "Memory Allocated: 3.66 GB\n",
      "0.04155468940734863\n"
     ]
    }
   ],
   "source": [
    "inputs_vfe = model.vfe(inputs)\n",
    "print(f\"Memory Allocated: {torch.cuda.memory_allocated(0) / (1024 ** 3):.2f} GB\")\n",
    "\n",
    "inputs_3d = model.backbone_3d(inputs_vfe)\n",
    "print(f\"Memory Allocated: {torch.cuda.memory_allocated(0) / (1024 ** 3):.2f} GB\")\n",
    "\n",
    "inputs_bev = model.map_to_bev_module(inputs_3d)\n",
    "import time\n",
    "start_time = time.time()\n",
    "print(f\"Memory Allocated: {torch.cuda.memory_allocated(0) / (1024 ** 3):.2f} GB\")\n",
    "inputs_2d = model.backbone_2d(inputs_bev)\n",
    "print(f\"Memory Allocated: {torch.cuda.memory_allocated(0) / (1024 ** 3):.2f} GB\")\n",
    "print(time.time()-start_time)\n",
    "start_time = time.time()\n",
    "print(f\"Memory Allocated: {torch.cuda.memory_allocated(0) / (1024 ** 3):.2f} GB\")\n",
    "\n",
    "model.dense_head(inputs_2d)\n",
    "print(f\"Memory Allocated: {torch.cuda.memory_allocated(0) / (1024 ** 3):.2f} GB\")\n",
    "\n",
    "print(time.time()-start_time)\n",
    "\n",
    "# inputs_bev\n",
    "# inputs_bev[\"spatial_features_2d\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae5a9e35-ab4f-497a-a6e1-6ca005b969f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs_vfe[\"spatial_features\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d7730b3-ce89-45b0-bcb3-056b207423ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs_3d.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e00ee598-7fca-40f4-90e0-fe302ffe9589",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    DSVT_2d_Backbone = model.backbone_2d\n",
    "    # dsvtblocks_list = DSVT_Backbone.stage_0\n",
    "    # layer_norms_list = DSVT_Backbone.residual_norm_stage_0\n",
    "    # inputs = model.vfe(inputs)\n",
    "    # voxel_info = DSVT_Backbone.input_layer(inputs)\n",
    "    # set_voxel_inds_list = [[voxel_info[f'set_voxel_inds_stage{s}_shift{i}'] for i in range(2)] for s in range(1)]\n",
    "    # set_voxel_masks_list = [[voxel_info[f'set_voxel_mask_stage{s}_shift{i}'] for i in range(2)] for s in range(1)]\n",
    "    # pos_embed_list = [[[voxel_info[f'pos_embed_stage{s}_block{b}_shift{i}'] for i in range(2)] for b in range(4)] for s in range(1)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc9e7635-abd0-4697-8992-91cecb2b6479",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_names = [\n",
    "    # 'voxel_features',\n",
    "    # 'use_lead_xyz',\n",
    "    # 'batch_size',\n",
    "    # 'pillar_features',\n",
    "    # 'voxel_coords',\n",
    "    'spatial_features'\n",
    "]\n",
    "output_names = [\"output\",]\n",
    "trt_path = './deploy_pillar_sfaw_2d_rev/dsvt_2d.engine'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74f5592a-abb8-4d85-ba0f-d1cb80ea6bca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'spatial_features': tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]]], device='cuda:0',\n",
       "        grad_fn=<ViewBackward0>)}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dict = {}\n",
    "input_dict={}\n",
    "# input_dict['voxel_features'] = inputs_bev['voxel_features']\n",
    "# input_dict['use_lead_xyz'] = inputs_bev['use_lead_xyz']\n",
    "# input_dict['batch_size'] = torch.tensor(inputs_bev['batch_size']).to(\"cuda:0\")\n",
    "# input_dict['pillar_features'] = inputs_bev['pillar_features']\n",
    "# input_dict['voxel_coords'] = inputs_bev['voxel_coords']\n",
    "input_dict['spatial_features'] = inputs_bev['spatial_features']\n",
    "input_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e551de7-7dc0-4a78-92b2-a58f0277248f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = input_dict['voxel_features']\n",
    "# outputs = 7*[None]\n",
    "# outputs[0] = torch.empty(input_dict['voxel_features'].shape).to('cuda:0')\n",
    "# outputs[1] = torch.empty(input_dict['use_lead_xyz'].shape).to('cuda:0')\n",
    "# outputs[2] = torch.empty(input_dict['batch_size'].shape).to('cuda:0')\n",
    "# outputs[3] = torch.empty(input_dict['pillar_features'].shape).to('cuda:0')\n",
    "# outputs[4] = torch.empty(input_dict['voxel_coords'].shape).to('cuda:0')\n",
    "# outputs[5] = torch.empty(input_dict['spatial_features'].shape).to('cuda:0')\n",
    "# outputs[6] = torch.empty(input_dict['spatial_features'].shape).to('cuda:0')\n",
    "# output = torch.empty(input_dict['spatial_features'].shape).to('cuda:0')\n",
    "# output = input_dict['spatial_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6591503-c201-4084-b6f1-f010563303b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_dict['pillar_features'].shape\n",
    "# engine.get_tensor_profile_shape(\"output\", 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6079288e-e20e-4e97-a453-587bcabb82c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output.size()\n",
    "# output = torch.empty([10000, 10000]).to('cuda:0')\n",
    "# set_voxel_inds_list[0][0].int().size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83f34fc0-a9a9-4f47-926f-243990444dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensor([[-1.0312, -0.2234, -0.2581,  ..., -1.2207,  0.0303, -0.2534],\n",
    "#         [ 0.0000,  0.0686,  0.0000,  ...,  0.0079,  0.0000,  0.0000],\n",
    "#         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
    "#         ...,\n",
    "#         [ 0.5312,  0.4485,  0.0000,  ...,  0.0691,  0.0000,  0.5523],\n",
    "#         [ 0.0000,  0.4938,  0.0000,  ...,  0.0557,  0.0000,  0.0000],\n",
    "#         [ 0.0000,  0.4529,  0.0000,  ...,  0.0210,  0.0000,  0.0000]],\n",
    "#        device='cuda:0', grad_fn=<CloneBackward0>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04f01935-fb7e-4baa-b925-8ce9c77c9da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trt_engine(path: str) -> trt.ICudaEngine:\n",
    "    \"\"\"Deserialize TensorRT engine from disk.\n",
    "\n",
    "    Args:\n",
    "        path (str): The disk path to read the engine.\n",
    "\n",
    "    Returns:\n",
    "        tensorrt.ICudaEngine: The TensorRT engine loaded from disk.\n",
    "    \"\"\"\n",
    "    # load_tensorrt_plugin()\n",
    "    with trt.Logger() as logger, trt.Runtime(logger) as runtime:\n",
    "        with open(path, mode='rb') as f:\n",
    "            engine_bytes = f.read()\n",
    "        engine = runtime.deserialize_cuda_engine(engine_bytes)\n",
    "        print(f\"TensorRT engine {path} successfully loaded.\")\n",
    "        return engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7216823-eba6-4339-a065-596acbdc2857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorRT engine ./deploy_pillar_sfaw_2d_rev/dsvt_2d.engine successfully loaded.\n",
      "[04/19/2024-01:32:31] [TRT] [W] CUDA lazy loading is not enabled. Enabling it can significantly reduce device memory usage and speed up TensorRT initialization. See \"Lazy Loading\" section of CUDA documentation https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#lazy-loading\n"
     ]
    }
   ],
   "source": [
    "trt.init_libnvinfer_plugins(None, '')\n",
    "if isinstance(trt_path, str):\n",
    "    engine = load_trt_engine(trt_path)\n",
    "\n",
    "if not isinstance(engine, trt.ICudaEngine):\n",
    "    raise TypeError(f'`engine` should be str or trt.ICudaEngine, \\\n",
    "        but given: {type(engine)}')\n",
    "\n",
    "context = engine.create_execution_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8568c94-f0ae-4956-b222-a29e89eba1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# context.set_tensor_address(\"src\", ptr)\n",
    "engine.get_tensor_profile_shape(\"output\", 0)\n",
    "output = torch.empty([1, 384, 468, 468]).to('cuda:0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf247ae6-0eaf-4d61-b93b-e456ddee1212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spatial_features'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inputs.items()\n",
    "engine.get_tensor_name(0)\n",
    "# engine.get_tensor_name(1)\n",
    "# engine.get_tensor_name(2)\n",
    "# engine.get_tensor_name(3)\n",
    "# engine.get_tensor_name(4)\n",
    "# engine.get_tensor_name(5)\n",
    "# engine.get_tensor_name(6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "01b51597-91fa-48c1-a355-d68ae05dc4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_shape = engine.get_tensor_profile_shape(\"output\", 0)\n",
    "# output_shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9efc2917-a70c-48a3-84ae-076fd7c41a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# src_shape = engine.get_tensor_profile_shape(\"src\", 0)[0]\n",
    "# output = torch.empty([output_shape[0]]).to('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "931c8441-7ec1-471f-8c8d-d1b98e68a512",
   "metadata": {},
   "outputs": [],
   "source": [
    "# engine.get_tensor_profile_values(0,\"src\")\n",
    "# input_host_mem = cuda.pagelocked_empty(trt.volume(src_shape) * trt.float32.itemsize)\n",
    "\n",
    "# bindings = [None] * (len(input_names) + len(output_names))\n",
    "\n",
    "# bindings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "921d19e3-5edb-4ac9-bdd0-ea18c56e7b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# context.execute_async_v3(\n",
    "#             bindings,\n",
    "#             torch.cuda.current_stream().cuda_stream,\n",
    "#         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d444676c-503c-4cba-8b36-bce4065b3361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'output'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# engine.get_profile_shape(0,\"src\")\n",
    "# engine.get_tensor_location(\"src\")\n",
    "# engine.get_tensor_format(\"src\")\n",
    "engine.get_tensor_name(1)\n",
    "# engine.get_tensor_profile_values(0,\"src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "10535336-8c49-49b6-ab4a-25ed756c3f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# profile = self.engine.get_profile_shape(profile_id, input_name)\n",
    "# assert input_tensor.dim() == len(\n",
    "#     profile[0]), 'Input dim is different from engine profile.'\n",
    "# for s_min, s_input, s_max in zip(eval(repr(profile[0])), input_tensor.shape,\n",
    "#                                  eval(repr(profile[2]))):\n",
    "#     assert s_min <= s_input <= s_max, \\\n",
    "#         f'Input shape of {input_name} should be between ' \\\n",
    "#         + f'{profile[0]} and {profile[2]}' \\\n",
    "#         + f' but get {tuple(input_tensor.shape)}.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "497d0c72-81c4-4ec1-a5d4-30e60288239b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_name: spatial_features\n",
      "profile : [(1, 192, 468, 468), (1, 192, 468, 468), (1, 192, 468, 468)]\n",
      "type : torch.float32\n",
      "shape : torch.Size([1, 192, 468, 468])\n",
      "======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2355162/4173236747.py:7: DeprecationWarning: Use get_tensor_profile_shape instead.\n",
      "  profile = engine.get_profile_shape(profile_id,input_name)\n"
     ]
    }
   ],
   "source": [
    "bindings = [None] * (len(input_names) + len(output_names))\n",
    "\n",
    "# https://github.dev/Haiyang-W/DSVT , dsvt.py -> 384line\n",
    "profile_id = 0\n",
    "idx = 0\n",
    "for input_name, input_tensor in input_dict.items():    \n",
    "    profile = engine.get_profile_shape(profile_id,input_name)\n",
    "    if input_tensor.dtype == torch.long:\n",
    "        input_tensor=input_tensor.int()\n",
    "        print(\"convert long to int\")\n",
    "    print(f'input_name: {input_name}')\n",
    "    print(f'profile : {profile}')\n",
    "    print(f'type : {input_tensor.dtype}')\n",
    "    print(f'shape : {input_tensor.size()}')\n",
    "    print(\"======\")\n",
    "    context.set_input_shape(input_name,tuple(input_tensor.shape))\n",
    "    bindings[idx] = input_tensor.contiguous().data_ptr()\n",
    "    idx+=1\n",
    "# get_binding_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6ff836cf-3242-4b63-b934-291f1358243e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[139733673967616, None]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bindings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b91630fd-ed8f-4c62-8c57-c1635cb7b98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.shape\n",
    "# profile = engine.get_profile_shape(0,\"output\")\n",
    "\n",
    "output_shape = profile[0]\n",
    "# output = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "386a6aab-5bb9-4a95-8bbe-80852b012ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# context.set_input_shape(\"output\",tuple(output_shape))\n",
    "\n",
    "bindings[-1] = output.data_ptr()\n",
    "# for idx, output in enumerate(outputs):\n",
    "    # print(output.shape)\n",
    "    # bindings[idx+6] = output.data_ptr()\n",
    "\n",
    "# for output_name in output_names:\n",
    "    # print(output_name)\n",
    "    # idx = self.engine.get_binding_index(output_name)\n",
    "    # dtype = torch_dtype_from_trt(self.engine.get_binding_dtype(idx))\n",
    "    # shape = eval(repr(self.context.get_binding_shape(idx)))\n",
    "\n",
    "    # device = torch_device_from_trt(self.engine.get_location(idx))\n",
    "    # output = torch.empty(size=shape, dtype=dtype, device=device)\n",
    "    # outputs[output_name] = output\n",
    "    # bindings[idx] = output.data_ptr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6453eac7-a545-4525-8b66-df6935d545ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[139733673967616, 139728573693952]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bindings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b1f0b133-b95d-4c5c-ab59-18561894d08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory Allocated: 3.22 GB\n",
      "Memory Allocated: 3.22 GB\n",
      "0.05564403533935547\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "print(f\"Memory Allocated: {torch.cuda.memory_allocated(0) / (1024 ** 3):.2f} GB\")\n",
    "\n",
    "context.execute_v2(\n",
    "            bindings\n",
    "        )\n",
    "print(f\"Memory Allocated: {torch.cuda.memory_allocated(0) / (1024 ** 3):.2f} GB\")\n",
    "\n",
    "print(time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "32a0269b-6d89-4e7d-b1b6-9212a013a864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 384, 468, 468])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a71c5274-a564-4345-8e2b-df039e41d081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.3520, 0.7090, 0.6403,  ..., 0.6391, 0.5351, 0.9621],\n",
       "          [0.6059, 0.6821, 0.6289,  ..., 0.6430, 0.7770, 1.0879],\n",
       "          [0.4052, 0.5088, 0.1898,  ..., 0.1131, 0.3867, 0.8935],\n",
       "          ...,\n",
       "          [0.4514, 0.6178, 0.3753,  ..., 0.3189, 0.4214, 0.8849],\n",
       "          [0.5247, 0.6775, 0.6047,  ..., 0.6434, 0.6046, 0.9232],\n",
       "          [0.5045, 0.6075, 0.5154,  ..., 0.5288, 0.6361, 0.7326]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0208,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.0000, 0.1979, 0.2160,  ..., 0.0775, 0.1823, 0.2410],\n",
       "          [0.3319, 0.1860, 0.0934,  ..., 0.2182, 0.0971, 0.1500],\n",
       "          [0.1251, 0.0000, 0.1882,  ..., 0.0000, 0.3053, 0.0000],\n",
       "          ...,\n",
       "          [0.4010, 0.3580, 0.2028,  ..., 0.0391, 0.5095, 0.0000],\n",
       "          [0.0689, 0.0000, 0.0067,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.3874, 0.0000,  ..., 0.3753, 0.0000, 0.3984]],\n",
       "\n",
       "         [[0.8989, 0.0000, 0.3568,  ..., 0.0000, 0.3610, 0.1620],\n",
       "          [1.0730, 0.7344, 0.2638,  ..., 0.4773, 0.4265, 0.0000],\n",
       "          [0.5357, 0.1370, 0.2929,  ..., 0.0000, 0.2119, 0.8188],\n",
       "          ...,\n",
       "          [1.0300, 0.6118, 0.7511,  ..., 0.1708, 0.5602, 0.0000],\n",
       "          [0.9800, 0.7472, 0.3269,  ..., 0.0637, 0.2289, 1.0750],\n",
       "          [0.9412, 0.0376, 0.7666,  ..., 0.0265, 0.7341, 0.0000]],\n",
       "\n",
       "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "66021eb8-8297-480f-aaf9-0aa89d087f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# context.execute_async_v3(bindings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "efaa2d63-83fe-413f-8157-b146f30a51b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "####\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5fa25c1a-ff2b-4d25-8aa8-9429fc07a162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # engine = load_engine(engine_file_path)\n",
    "# # Load the TensorRT engine from the file\n",
    "# with open(engine_file_path, 'rb') as f, trt.Runtime(trt.Logger(trt.Logger.WARNING)) as runtime:\n",
    "#     engine = runtime.deserialize_cuda_engine(f.read())\n",
    "#     context = engine.create_execution_context()\n",
    "# # engine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70756800-a4c1-4d60-911a-b21583b49e9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "de49cd73-4c7f-4d4a-9d87-a26f54ac0819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_bindings = engine.num_bindings\n",
    "# binding_info = []\n",
    "# for i in range(num_bindings):\n",
    "#     binding_info.append({\n",
    "#         'index': i,\n",
    "#         'name': engine.get_binding_name(i),\n",
    "#         'shape': engine.get_binding_shape(i),\n",
    "#         'dtype': trt.nptype(engine.get_binding_dtype(i))\n",
    "#     })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "afd69722-60da-4971-bbeb-5e026dfcf9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04/19/2024-01:32:39] [TRT] [W] CUDA lazy loading is not enabled. Enabling it can significantly reduce device memory usage and speed up TensorRT initialization. See \"Lazy Loading\" section of CUDA documentation https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#lazy-loading\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tensorrt.tensorrt.ICudaEngine' object has no attribute 'get_binding_shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m context \u001b[38;5;241m=\u001b[39m engine\u001b[38;5;241m.\u001b[39mcreate_execution_context()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# 입력 및 출력 버퍼를 할당합니다.\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m input_shape \u001b[38;5;241m=\u001b[39m \u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_binding_shape\u001b[49m(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      5\u001b[0m output_shape \u001b[38;5;241m=\u001b[39m engine\u001b[38;5;241m.\u001b[39mget_binding_shape(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m      6\u001b[0m input_host_mem \u001b[38;5;241m=\u001b[39m cuda\u001b[38;5;241m.\u001b[39mpagelocked_empty(trt\u001b[38;5;241m.\u001b[39mvolume(input_shape) \u001b[38;5;241m*\u001b[39m trt\u001b[38;5;241m.\u001b[39mfloat32\u001b[38;5;241m.\u001b[39mitemsize)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tensorrt.tensorrt.ICudaEngine' object has no attribute 'get_binding_shape'"
     ]
    }
   ],
   "source": [
    "context = engine.create_execution_context()\n",
    "\n",
    "# 입력 및 출력 버퍼를 할당합니다.\n",
    "input_shape = engine.get_binding_shape(0)\n",
    "output_shape = engine.get_binding_shape(1)\n",
    "input_host_mem = cuda.pagelocked_empty(trt.volume(input_shape) * trt.float32.itemsize)\n",
    "output_host_mem = cuda.pagelocked_empty(trt.volume(output_shape) * trt.float32.itemsize)\n",
    "input_device_mem = cuda.mem_alloc(input_host_mem.nbytes)\n",
    "output_device_mem = cuda.mem_alloc(output_host_mem.nbytes)\n",
    "\n",
    "# 이미지 전처리\n",
    "image = preprocess_image(image_path, input_shape)\n",
    "\n",
    "# 입력을 GPU 메모리로 복사합니다.\n",
    "cuda.memcpy_htod(input_device_mem, image.flatten())\n",
    "\n",
    "# 추론 실행\n",
    "bindings = [int(input_device_mem), int(output_device_mem)]\n",
    "context.execute_v2(bindings)\n",
    "\n",
    "# 결과를 GPU에서 CPU로 복사합니다.\n",
    "cuda.memcpy_dtoh(output_host_mem, output_device_mem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab89aeb5-0085-4647-a70e-9d7deb962cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dict = {}\n",
    "input_dict['data_dict']={}\n",
    "input_dict['data_dict']['voxel_features'] = ort_outs[0]\n",
    "input_dict['data_dict']['use_lead_xyz'] = ort_outs[1]\n",
    "input_dict['data_dict']['batch_size'] = ort_outs[2]\n",
    "input_dict['data_dict']['pillar_features'] = ort_outs[3]\n",
    "input_dict['data_dict']['voxel_coords'] = ort_outs[4]\n",
    "input_dict['data_dict']['spatial_features'] = ort_outs[5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddcc566-ac78-4fdb-8da8-8ad57d4b5c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_name = \"./deploy_pillar_sfaw_2d/dsvt_2d_bb\"\n",
    "ts_path = f\"{base_name}.ts\"\n",
    "onnx_path = f\"{base_name}.onnx\"\n",
    "\n",
    "ort_session = ort.InferenceSession(onnx_path)\n",
    "\n",
    "ort_inputs = {\n",
    "    'voxel_features' : input_dict['data_dict']['voxel_features'],\n",
    "    'use_lead_xyz' : input_dict['data_dict']['use_lead_xyz'],\n",
    "    'batch_size' :  input_dict['data_dict']['batch_size'],\n",
    "    'pillar_features' : input_dict['data_dict']['pillar_features'],\n",
    "    'voxel_coords' : input_dict['data_dict']['voxel_coords'],\n",
    "    'spatial_features' : input_dict['data_dict']['spatial_features']\n",
    "}\n",
    "ort_outs = ort_session.run(None, ort_inputs)\n",
    "ort_outs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7401c11a-c2a4-47c6-be1a-167250b9553c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177cb6d4-595d-4c0d-9677-313dda7c58bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dict = {}\n",
    "input_dict = {}\n",
    "input_dict['data_dict']={}\n",
    "input_dict['data_dict']['voxel_features'] = ort_outs[0]\n",
    "input_dict['data_dict']['use_lead_xyz'] = ort_outs[1]\n",
    "input_dict['data_dict']['batch_size'] = ort_outs[2]\n",
    "input_dict['data_dict']['pillar_features'] = ort_outs[3]\n",
    "input_dict['data_dict']['voxel_coords'] = ort_outs[4]\n",
    "input_dict['data_dict']['spatial_features'] = ort_outs[5]\n",
    "input_dict['data_dict']['spatial_features_2d'] = ort_outs[6]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99099044-0103-47f8-ad08-d6a7cd565723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test onnx\n",
    "base_name = \"./deploy_pillar_sfaw_head/dsvt_head\"\n",
    "ts_path = f\"{base_name}.ts\"\n",
    "onnx_path = f\"{base_name}.onnx\"\n",
    "\n",
    "\n",
    "ort_session = ort.InferenceSession(onnx_path)\n",
    "\n",
    "ort_inputs = {\n",
    "    'voxel_features' : input_dict['data_dict']['voxel_features'],\n",
    "    'use_lead_xyz' : input_dict['data_dict']['use_lead_xyz'],\n",
    "    'batch_size' :  input_dict['data_dict']['batch_size'],\n",
    "    'pillar_features' : input_dict['data_dict']['pillar_features'],\n",
    "    'voxel_coords' : input_dict['data_dict']['voxel_coords'],\n",
    "    'spatial_features' : input_dict['data_dict']['spatial_features'],\n",
    "    'spatial_features_2d' : input_dict['data_dict']['spatial_features_2d']\n",
    "}\n",
    "\n",
    "ort_outs = ort_session.run(None, ort_inputs)\n",
    "ort_outs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
