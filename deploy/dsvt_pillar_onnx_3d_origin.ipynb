{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80f66a20-a14b-4980-93b4-21ebd5c2b60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-11 14:56:08,428   INFO  Loading Custom dataset.\n",
      "2024-04-11 14:56:08,428   INFO  Loading Custom dataset.\n",
      "2024-04-11 14:56:08,431   INFO  Total samples for CUSTOM dataset: 0\n",
      "2024-04-11 14:56:08,431   INFO  Total samples for CUSTOM dataset: 0\n",
      "2024-04-11 14:56:08,680   INFO  ==> Loading parameters from checkpoint ./pillar/model.pth to GPU\n",
      "2024-04-11 14:56:08,680   INFO  ==> Loading parameters from checkpoint ./pillar/model.pth to GPU\n",
      "2024-04-11 14:56:08,993   INFO  ==> Checkpoint trained from version: pcdet+0.6.0+255db8f\n",
      "2024-04-11 14:56:08,993   INFO  ==> Checkpoint trained from version: pcdet+0.6.0+255db8f\n",
      "2024-04-11 14:56:09,137   INFO  ==> Done (loaded 391/391)\n",
      "2024-04-11 14:56:09,137   INFO  ==> Done (loaded 391/391)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pcdet.config import cfg, cfg_from_yaml_file\n",
    "from pcdet.models import build_network\n",
    "from pcdet.datasets import build_dataloader\n",
    "from pcdet.utils import common_utils\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "import torch.nn as nn\n",
    "\n",
    "from typing import Sequence, NamedTuple\n",
    "\n",
    "\n",
    "####### load model #######\n",
    "# cfg_file = \"./cfgs/dsvt_models/dsvt_plain_1f_onestage.yaml\"\n",
    "# cfg_from_yaml_file(cfg_file, cfg)\n",
    "# if os.path.exists('./deploy_files')==False:\n",
    "#     os.mkdir('./deploy_files')\n",
    "# log_file = './deploy_files/log_trt.log'\n",
    "\n",
    "cfg_file = \"./pillar/config.yaml\"\n",
    "cfg_from_yaml_file(cfg_file, cfg)\n",
    "if os.path.exists('./deploy_pillar_sfaw_3d_origin')==False:\n",
    "    os.mkdir('./deploy_pillar_sfaw_3d_origin')\n",
    "log_file = './deploy_pillar_sfaw_3d_origin/log_trt.log'\n",
    "\n",
    "logger = common_utils.create_logger(log_file, rank=0)\n",
    "test_set, test_loader, sampler = build_dataloader(\n",
    "    dataset_cfg=cfg.DATA_CONFIG,\n",
    "    class_names=cfg.CLASS_NAMES,\n",
    "    batch_size=1,\n",
    "    dist=False, workers=8, logger=logger, training=False\n",
    ")\n",
    "\n",
    "model = build_network(model_cfg=cfg.MODEL, num_class=len(cfg.CLASS_NAMES), dataset=test_set)\n",
    "ckpt = \"./pillar/model.pth\"\n",
    "\n",
    "model.load_params_from_file(filename=ckpt, logger=logger, to_cpu=False, pre_trained_path=None)\n",
    "model.eval()\n",
    "model.cuda()\n",
    "####### load model #######\n",
    "\n",
    "####### read input #######\n",
    "batch_dict = torch.load(\"/mnt/nas2/users/eslim/onnx/sfaw/input_dict.pth\", map_location=\"cuda\")\n",
    "inputs = batch_dict\n",
    "####### read input #######\n",
    "\n",
    "####### DSVT #######\n",
    "class AllDSVTBlocksTRT(nn.Module):\n",
    "    def __init__(self, dsvtblocks_list, layer_norms_list):\n",
    "        super().__init__()\n",
    "        self.layer_norms_list = layer_norms_list\n",
    "        self.dsvtblocks_list = dsvtblocks_list\n",
    "    def forward(\n",
    "        self,\n",
    "        pillar_features, \n",
    "        set_voxel_inds_tensor_shift_0,\n",
    "        set_voxel_inds_tensor_shift_1,\n",
    "        set_voxel_masks_tensor_shift_0, \n",
    "        set_voxel_masks_tensor_shift_1,\n",
    "        pos_embed_tensor,\n",
    "    ):\n",
    "        outputs = pillar_features\n",
    "\n",
    "        residual = outputs\n",
    "        blc_id = 0\n",
    "        set_id = 0\n",
    "        set_voxel_inds = set_voxel_inds_tensor_shift_0[set_id:set_id+1].squeeze(0)\n",
    "        set_voxel_masks = set_voxel_masks_tensor_shift_0[set_id:set_id+1].squeeze(0)\n",
    "        pos_embed = pos_embed_tensor[blc_id:blc_id+1, set_id:set_id+1].squeeze(0).squeeze(0)\n",
    "        inputs = (outputs, set_voxel_inds, set_voxel_masks, pos_embed, True)\n",
    "        outputs = self.dsvtblocks_list[blc_id].encoder_list[set_id](*inputs)\n",
    "        set_id = 1\n",
    "        set_voxel_inds = set_voxel_inds_tensor_shift_0[set_id:set_id+1].squeeze(0)\n",
    "        set_voxel_masks = set_voxel_masks_tensor_shift_0[set_id:set_id+1].squeeze(0)\n",
    "        pos_embed = pos_embed_tensor[blc_id:blc_id+1, set_id:set_id+1].squeeze(0).squeeze(0)\n",
    "        inputs = (outputs, set_voxel_inds, set_voxel_masks, pos_embed, True)\n",
    "        outputs = self.dsvtblocks_list[blc_id].encoder_list[set_id](*inputs)\n",
    "        \n",
    "        outputs = self.layer_norms_list[blc_id](residual + outputs)\n",
    "\n",
    "        residual = outputs\n",
    "        blc_id = 1\n",
    "        set_id = 0\n",
    "        set_voxel_inds = set_voxel_inds_tensor_shift_1[set_id:set_id+1].squeeze(0)\n",
    "        set_voxel_masks = set_voxel_masks_tensor_shift_1[set_id:set_id+1].squeeze(0)\n",
    "        pos_embed = pos_embed_tensor[blc_id:blc_id+1, set_id:set_id+1].squeeze(0).squeeze(0)\n",
    "        inputs = (outputs, set_voxel_inds, set_voxel_masks, pos_embed, True)\n",
    "        outputs = self.dsvtblocks_list[blc_id].encoder_list[set_id](*inputs)\n",
    "        set_id = 1\n",
    "        set_voxel_inds = set_voxel_inds_tensor_shift_1[set_id:set_id+1].squeeze(0)\n",
    "        set_voxel_masks = set_voxel_masks_tensor_shift_1[set_id:set_id+1].squeeze(0)\n",
    "        pos_embed = pos_embed_tensor[blc_id:blc_id+1, set_id:set_id+1].squeeze(0).squeeze(0)\n",
    "        inputs = (outputs, set_voxel_inds, set_voxel_masks, pos_embed, True)\n",
    "        outputs = self.dsvtblocks_list[blc_id].encoder_list[set_id](*inputs)\n",
    "        \n",
    "        outputs = self.layer_norms_list[blc_id](residual + outputs)\n",
    "\n",
    "        residual = outputs\n",
    "        blc_id = 2\n",
    "        set_id = 0\n",
    "        set_voxel_inds = set_voxel_inds_tensor_shift_0[set_id:set_id+1].squeeze(0)\n",
    "        set_voxel_masks = set_voxel_masks_tensor_shift_0[set_id:set_id+1].squeeze(0)\n",
    "        pos_embed = pos_embed_tensor[blc_id:blc_id+1, set_id:set_id+1].squeeze(0).squeeze(0)\n",
    "        inputs = (outputs, set_voxel_inds, set_voxel_masks, pos_embed, True)\n",
    "        outputs = self.dsvtblocks_list[blc_id].encoder_list[set_id](*inputs)\n",
    "        set_id = 1\n",
    "        set_voxel_inds = set_voxel_inds_tensor_shift_0[set_id:set_id+1].squeeze(0)\n",
    "        set_voxel_masks = set_voxel_masks_tensor_shift_0[set_id:set_id+1].squeeze(0)\n",
    "        pos_embed = pos_embed_tensor[blc_id:blc_id+1, set_id:set_id+1].squeeze(0).squeeze(0)\n",
    "        inputs = (outputs, set_voxel_inds, set_voxel_masks, pos_embed, True)\n",
    "        outputs = self.dsvtblocks_list[blc_id].encoder_list[set_id](*inputs)\n",
    "        \n",
    "        outputs = self.layer_norms_list[blc_id](residual + outputs)\n",
    "\n",
    "        residual = outputs\n",
    "        blc_id = 3\n",
    "        set_id = 0\n",
    "        set_voxel_inds = set_voxel_inds_tensor_shift_1[set_id:set_id+1].squeeze(0)\n",
    "        set_voxel_masks = set_voxel_masks_tensor_shift_1[set_id:set_id+1].squeeze(0)\n",
    "        pos_embed = pos_embed_tensor[blc_id:blc_id+1, set_id:set_id+1].squeeze(0).squeeze(0)\n",
    "        inputs = (outputs, set_voxel_inds, set_voxel_masks, pos_embed, True)\n",
    "        outputs = self.dsvtblocks_list[blc_id].encoder_list[set_id](*inputs)\n",
    "        set_id = 1\n",
    "        set_voxel_inds = set_voxel_inds_tensor_shift_1[set_id:set_id+1].squeeze(0)\n",
    "        set_voxel_masks = set_voxel_masks_tensor_shift_1[set_id:set_id+1].squeeze(0)\n",
    "        pos_embed = pos_embed_tensor[blc_id:blc_id+1, set_id:set_id+1].squeeze(0).squeeze(0)\n",
    "        inputs = (outputs, set_voxel_inds, set_voxel_masks, pos_embed, True)\n",
    "        outputs = self.dsvtblocks_list[blc_id].encoder_list[set_id](*inputs)\n",
    "        \n",
    "        outputs = self.layer_norms_list[blc_id](residual + outputs)\n",
    "\n",
    "        return outputs\n",
    "####### DSVT #######\n",
    "\n",
    "####### torch to onnx #######\n",
    "with torch.no_grad():\n",
    "    DSVT_Backbone = model.backbone_3d\n",
    "    dsvtblocks_list = DSVT_Backbone.stage_0\n",
    "    layer_norms_list = DSVT_Backbone.residual_norm_stage_0\n",
    "    inputs = model.vfe(inputs)\n",
    "    voxel_info = DSVT_Backbone.input_layer(inputs)\n",
    "    set_voxel_inds_list = [[voxel_info[f'set_voxel_inds_stage{s}_shift{i}'] for i in range(2)] for s in range(1)]\n",
    "    set_voxel_masks_list = [[voxel_info[f'set_voxel_mask_stage{s}_shift{i}'] for i in range(2)] for s in range(1)]\n",
    "    pos_embed_list = [[[voxel_info[f'pos_embed_stage{s}_block{b}_shift{i}'] for i in range(2)] for b in range(4)] for s in range(1)]\n",
    "\n",
    "    pillar_features = inputs['voxel_features']\n",
    "    alldsvtblockstrt_inputs = (\n",
    "        pillar_features,\n",
    "        set_voxel_inds_list[0][0],\n",
    "        set_voxel_inds_list[0][1],\n",
    "        set_voxel_masks_list[0][0],\n",
    "        set_voxel_masks_list[0][1],\n",
    "        torch.stack([torch.stack(v, dim=0) for v in pos_embed_list[0]], dim=0),\n",
    "    )\n",
    "\n",
    "    jit_mode = \"trace\"\n",
    "    input_names = [\n",
    "        'src',\n",
    "        'set_voxel_inds_tensor_shift_0', \n",
    "        'set_voxel_inds_tensor_shift_1', \n",
    "        'set_voxel_masks_tensor_shift_0', \n",
    "        'set_voxel_masks_tensor_shift_1',\n",
    "        'pos_embed_tensor'\n",
    "    ]\n",
    "    output_names = [\"output\",]\n",
    "    input_shapes = {\n",
    "        \"src\": {\n",
    "            \"min_shape\": [24629, 192],\n",
    "            \"opt_shape\": [24629, 192],\n",
    "            \"max_shape\": [24629, 192],\n",
    "        },\n",
    "        \"set_voxel_inds_tensor_shift_0\": {\n",
    "            \"min_shape\": [2, 1156, 36],\n",
    "            \"opt_shape\": [2, 1156, 36],\n",
    "            \"max_shape\": [2, 1156, 36],\n",
    "        },\n",
    "        \"set_voxel_inds_tensor_shift_1\": {\n",
    "            \"min_shape\": [2, 834, 36],\n",
    "            \"opt_shape\": [2, 834, 36],\n",
    "            \"max_shape\": [2, 834, 36],\n",
    "        },\n",
    "        \"set_voxel_masks_tensor_shift_0\": {\n",
    "            \"min_shape\": [2, 1156, 36],\n",
    "            \"opt_shape\": [2, 1156, 36],\n",
    "            \"max_shape\": [2, 1156, 36],\n",
    "        },\n",
    "        \"set_voxel_masks_tensor_shift_1\": {\n",
    "            \"min_shape\": [2, 834, 36],\n",
    "            \"opt_shape\": [2, 834, 36],\n",
    "            \"max_shape\": [2, 834, 36],\n",
    "        },\n",
    "        \"pos_embed_tensor\": {\n",
    "            \"min_shape\": [4, 2, 24629, 192],\n",
    "            \"opt_shape\": [4, 2, 24629, 192],\n",
    "            \"max_shape\": [4, 2, 24629, 192],\n",
    "        },\n",
    "    }\n",
    "\n",
    "\n",
    "    dynamic_axes = {\n",
    "        \"src\": {\n",
    "            0: \"voxel_number\",\n",
    "        },\n",
    "        \"set_voxel_inds_tensor_shift_0\": {\n",
    "            1: \"set_number_shift_0\",\n",
    "        },\n",
    "        \"set_voxel_inds_tensor_shift_1\": {\n",
    "            1: \"set_number_shift_1\",\n",
    "        },\n",
    "        \"set_voxel_masks_tensor_shift_0\": {\n",
    "            1: \"set_number_shift_0\",\n",
    "        },\n",
    "        \"set_voxel_masks_tensor_shift_1\": {\n",
    "            1: \"set_number_shift_1\",\n",
    "        },\n",
    "        \"pos_embed_tensor\": {\n",
    "            2: \"voxel_number\",\n",
    "        },\n",
    "        \"output\": {\n",
    "            0: \"voxel_number\",\n",
    "        }\n",
    "    }\n",
    "\n",
    "    base_name = \"./deploy_pillar_sfaw_3d_origin\"\n",
    "    ts_path = f\"{base_name}.ts\"\n",
    "    onnx_path = f\"{base_name}.onnx\"\n",
    "\n",
    "    allptransblocktrt = AllDSVTBlocksTRT(dsvtblocks_list, layer_norms_list).eval().cuda()\n",
    "    torch.onnx.export(\n",
    "        allptransblocktrt,\n",
    "        alldsvtblockstrt_inputs,\n",
    "        onnx_path, input_names=input_names,\n",
    "        output_names=output_names, dynamic_axes=dynamic_axes,\n",
    "        opset_version=14,\n",
    "    )\n",
    "    # test onnx\n",
    "    ort_session = ort.InferenceSession(onnx_path)\n",
    "    def to_numpy(tensor):\n",
    "        return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "    \n",
    "    # compute ONNX Runtime output prediction\n",
    "    ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(pillar_features),\n",
    "                  ort_session.get_inputs()[1].name: to_numpy(set_voxel_inds_list[0][0]),\n",
    "                  ort_session.get_inputs()[2].name: to_numpy(set_voxel_inds_list[0][1]),\n",
    "                  ort_session.get_inputs()[3].name: to_numpy(set_voxel_masks_list[0][0]),\n",
    "                  ort_session.get_inputs()[4].name: to_numpy(set_voxel_masks_list[0][1]),\n",
    "                  ort_session.get_inputs()[5].name: to_numpy(torch.stack([torch.stack(v, dim=0) for v in pos_embed_list[0]], dim=0)),}\n",
    "    ort_outs = ort_session.run(None, ort_inputs) \n",
    "####### torch to onnx #######\n",
    "\n",
    "\n",
    "####### torch to trt engine #######\n",
    "# trtexec --onnx={path to onnx} --saveEngine={path to save trtengine} \\\n",
    "# --memPoolSize=workspace:4096 --verbose --buildOnly --device=1 --fp16 \\\n",
    "# --tacticSources=+CUDNN,+CUBLAS,-CUBLAS_LT,+EDGE_MASK_CONVOLUTIONS \\\n",
    "# --minShapes=src:3000x192,set_voxel_inds_tensor_shift_0:2x170x36,set_voxel_inds_tensor_shift_1:2x100x36,set_voxel_masks_tensor_shift_0:2x170x36,set_voxel_masks_tensor_shift_1:2x100x36,pos_embed_tensor:4x2x3000x192 \\\n",
    "# --optShapes=src:20000x192,set_voxel_inds_tensor_shift_0:2x1000x36,set_voxel_inds_tensor_shift_1:2x700x36,set_voxel_masks_tensor_shift_0:2x1000x36,set_voxel_masks_tensor_shift_1:2x700x36,pos_embed_tensor:4x2x20000x192 \\\n",
    "# --maxShapes=src:35000x192,set_voxel_inds_tensor_shift_0:2x1500x36,set_voxel_inds_tensor_shift_1:2x1200x36,set_voxel_masks_tensor_shift_0:2x1500x36,set_voxel_masks_tensor_shift_1:2x1200x36,pos_embed_tensor:4x2x35000x192 \\\n",
    "####### torch to trt engine #######"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
