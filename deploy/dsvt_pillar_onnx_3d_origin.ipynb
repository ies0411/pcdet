{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80f66a20-a14b-4980-93b4-21ebd5c2b60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: detected dubious ownership in repository at '/mnt/nas2/users/eslim/workspace/OpenPCDet'\n",
      "To add an exception for this directory, call:\n",
      "\n",
      "\tgit config --global --add safe.directory /mnt/nas2/users/eslim/workspace/OpenPCDet\n",
      "2024-04-16 13:20:19,989   INFO  Loading Custom dataset.\n",
      "2024-04-16 13:20:19,991   INFO  Total samples for CUSTOM dataset: 0\n",
      "2024-04-16 13:20:22,342   INFO  ==> Loading parameters from checkpoint ./pillar/model.pth to GPU\n",
      "2024-04-16 13:20:22,493   INFO  ==> Checkpoint trained from version: pcdet+0.6.0+255db8f\n",
      "2024-04-16 13:20:22,726   INFO  ==> Done (loaded 391/391)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============= Diagnostic Run torch.onnx.export version 2.0.1+cu118 =============\n",
      "verbose: False, log level: Level.ERROR\n",
      "======================= 0 NONE 0 NOTE 0 WARNING 0 ERROR ========================\n",
      "\n",
      "0.05576634407043457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/onnxconverter_common/float16.py:43: UserWarning: the float32 number 8.925729844122543e-08 will be truncated to 1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(pos_min, min_positive_val))\n",
      "/usr/local/lib/python3.8/dist-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -8.875807822050774e-08 will be truncated to -1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
      "/usr/local/lib/python3.8/dist-packages/onnxconverter_common/float16.py:53: UserWarning: the float32 number -2.107342389479072e-08 will be truncated to -1e-07\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_max, -min_positive_val))\n",
      "/usr/local/lib/python3.8/dist-packages/onnxconverter_common/float16.py:50: UserWarning: the float32 number -inf will be truncated to -10000.0\n",
      "  warnings.warn(\"the float32 number {} will be truncated to {}\".format(neg_min, -max_finite_val))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU\n",
      "0.23626136779785156\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-1.098e+00, -8.893e-02,  1.570e-01, ..., -1.048e+00,  3.809e-02,\n",
       "         -1.986e-01],\n",
       "        [-1.097e+00, -7.098e-02,  1.605e-01, ..., -1.083e+00,  4.245e-02,\n",
       "         -1.924e-01],\n",
       "        [-1.087e+00, -1.011e-01,  1.786e-01, ..., -1.056e+00,  2.637e-02,\n",
       "         -1.595e-01],\n",
       "        ...,\n",
       "        [-3.608e-01,  2.130e-01, -1.586e-01, ..., -1.233e+00, -1.638e-01,\n",
       "          1.677e-01],\n",
       "        [-6.187e-01,  3.523e-01, -1.115e-01, ..., -1.372e+00, -1.095e-01,\n",
       "         -5.441e-02],\n",
       "        [-6.133e-01,  3.215e-01, -1.253e-02, ..., -1.245e+00,  6.313e-04,\n",
       "         -1.378e-01]], dtype=float16)]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pcdet.config import cfg, cfg_from_yaml_file\n",
    "from pcdet.models import build_network\n",
    "from pcdet.datasets import build_dataloader\n",
    "from pcdet.utils import common_utils\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "import torch.nn as nn\n",
    "\n",
    "from typing import Sequence, NamedTuple\n",
    "\n",
    "\n",
    "####### load model #######\n",
    "# cfg_file = \"./cfgs/dsvt_models/dsvt_plain_1f_onestage.yaml\"\n",
    "# cfg_from_yaml_file(cfg_file, cfg)\n",
    "# if os.path.exists('./deploy_files')==False:\n",
    "#     os.mkdir('./deploy_files')\n",
    "# log_file = './deploy_files/log_trt.log'\n",
    "\n",
    "cfg_file = \"./pillar/config.yaml\"\n",
    "cfg_from_yaml_file(cfg_file, cfg)\n",
    "if os.path.exists('./deploy_pillar_sfaw_3d_origin')==False:\n",
    "    os.mkdir('./deploy_pillar_sfaw_3d_origin')\n",
    "log_file = './deploy_pillar_sfaw_3d_origin/log_trt.log'\n",
    "\n",
    "logger = common_utils.create_logger(log_file, rank=0)\n",
    "test_set, test_loader, sampler = build_dataloader(\n",
    "    dataset_cfg=cfg.DATA_CONFIG,\n",
    "    class_names=cfg.CLASS_NAMES,\n",
    "    batch_size=1,\n",
    "    dist=False, workers=8, logger=logger, training=False\n",
    ")\n",
    "\n",
    "model = build_network(model_cfg=cfg.MODEL, num_class=len(cfg.CLASS_NAMES), dataset=test_set)\n",
    "ckpt = \"./pillar/model.pth\"\n",
    "\n",
    "model.load_params_from_file(filename=ckpt, logger=logger, to_cpu=False, pre_trained_path=None)\n",
    "model.eval()\n",
    "model.cuda()\n",
    "####### load model #######\n",
    "\n",
    "####### read input #######\n",
    "batch_dict = torch.load(\"/mnt/nas2/users/eslim/onnx/sfaw/input_dict.pth\", map_location=\"cuda\")\n",
    "inputs = batch_dict\n",
    "####### read input #######\n",
    "\n",
    "####### DSVT #######\n",
    "class AllDSVTBlocksTRT(nn.Module):\n",
    "    def __init__(self, dsvtblocks_list, layer_norms_list):\n",
    "        super().__init__()\n",
    "        self.layer_norms_list = layer_norms_list\n",
    "        self.dsvtblocks_list = dsvtblocks_list\n",
    "    def forward(\n",
    "        self,\n",
    "        pillar_features, \n",
    "        set_voxel_inds_tensor_shift_0,\n",
    "        set_voxel_inds_tensor_shift_1,\n",
    "        set_voxel_masks_tensor_shift_0, \n",
    "        set_voxel_masks_tensor_shift_1,\n",
    "        pos_embed_tensor,\n",
    "    ):\n",
    "        outputs = pillar_features\n",
    "\n",
    "        residual = outputs\n",
    "        blc_id = 0\n",
    "        set_id = 0\n",
    "        set_voxel_inds = set_voxel_inds_tensor_shift_0[set_id:set_id+1].squeeze(0)\n",
    "        set_voxel_masks = set_voxel_masks_tensor_shift_0[set_id:set_id+1].squeeze(0)\n",
    "        pos_embed = pos_embed_tensor[blc_id:blc_id+1, set_id:set_id+1].squeeze(0).squeeze(0)\n",
    "        inputs = (outputs, set_voxel_inds, set_voxel_masks, pos_embed, True)\n",
    "        outputs = self.dsvtblocks_list[blc_id].encoder_list[set_id](*inputs)\n",
    "        set_id = 1\n",
    "        set_voxel_inds = set_voxel_inds_tensor_shift_0[set_id:set_id+1].squeeze(0)\n",
    "        set_voxel_masks = set_voxel_masks_tensor_shift_0[set_id:set_id+1].squeeze(0)\n",
    "        pos_embed = pos_embed_tensor[blc_id:blc_id+1, set_id:set_id+1].squeeze(0).squeeze(0)\n",
    "        inputs = (outputs, set_voxel_inds, set_voxel_masks, pos_embed, True)\n",
    "        outputs = self.dsvtblocks_list[blc_id].encoder_list[set_id](*inputs)\n",
    "        \n",
    "        outputs = self.layer_norms_list[blc_id](residual + outputs)\n",
    "\n",
    "        residual = outputs\n",
    "        blc_id = 1\n",
    "        set_id = 0\n",
    "        set_voxel_inds = set_voxel_inds_tensor_shift_1[set_id:set_id+1].squeeze(0)\n",
    "        set_voxel_masks = set_voxel_masks_tensor_shift_1[set_id:set_id+1].squeeze(0)\n",
    "        pos_embed = pos_embed_tensor[blc_id:blc_id+1, set_id:set_id+1].squeeze(0).squeeze(0)\n",
    "        inputs = (outputs, set_voxel_inds, set_voxel_masks, pos_embed, True)\n",
    "        outputs = self.dsvtblocks_list[blc_id].encoder_list[set_id](*inputs)\n",
    "        set_id = 1\n",
    "        set_voxel_inds = set_voxel_inds_tensor_shift_1[set_id:set_id+1].squeeze(0)\n",
    "        set_voxel_masks = set_voxel_masks_tensor_shift_1[set_id:set_id+1].squeeze(0)\n",
    "        pos_embed = pos_embed_tensor[blc_id:blc_id+1, set_id:set_id+1].squeeze(0).squeeze(0)\n",
    "        inputs = (outputs, set_voxel_inds, set_voxel_masks, pos_embed, True)\n",
    "        outputs = self.dsvtblocks_list[blc_id].encoder_list[set_id](*inputs)\n",
    "        \n",
    "        outputs = self.layer_norms_list[blc_id](residual + outputs)\n",
    "\n",
    "        residual = outputs\n",
    "        blc_id = 2\n",
    "        set_id = 0\n",
    "        set_voxel_inds = set_voxel_inds_tensor_shift_0[set_id:set_id+1].squeeze(0)\n",
    "        set_voxel_masks = set_voxel_masks_tensor_shift_0[set_id:set_id+1].squeeze(0)\n",
    "        pos_embed = pos_embed_tensor[blc_id:blc_id+1, set_id:set_id+1].squeeze(0).squeeze(0)\n",
    "        inputs = (outputs, set_voxel_inds, set_voxel_masks, pos_embed, True)\n",
    "        outputs = self.dsvtblocks_list[blc_id].encoder_list[set_id](*inputs)\n",
    "        set_id = 1\n",
    "        set_voxel_inds = set_voxel_inds_tensor_shift_0[set_id:set_id+1].squeeze(0)\n",
    "        set_voxel_masks = set_voxel_masks_tensor_shift_0[set_id:set_id+1].squeeze(0)\n",
    "        pos_embed = pos_embed_tensor[blc_id:blc_id+1, set_id:set_id+1].squeeze(0).squeeze(0)\n",
    "        inputs = (outputs, set_voxel_inds, set_voxel_masks, pos_embed, True)\n",
    "        outputs = self.dsvtblocks_list[blc_id].encoder_list[set_id](*inputs)\n",
    "        \n",
    "        outputs = self.layer_norms_list[blc_id](residual + outputs)\n",
    "\n",
    "        residual = outputs\n",
    "        blc_id = 3\n",
    "        set_id = 0\n",
    "        set_voxel_inds = set_voxel_inds_tensor_shift_1[set_id:set_id+1].squeeze(0)\n",
    "        set_voxel_masks = set_voxel_masks_tensor_shift_1[set_id:set_id+1].squeeze(0)\n",
    "        pos_embed = pos_embed_tensor[blc_id:blc_id+1, set_id:set_id+1].squeeze(0).squeeze(0)\n",
    "        inputs = (outputs, set_voxel_inds, set_voxel_masks, pos_embed, True)\n",
    "        outputs = self.dsvtblocks_list[blc_id].encoder_list[set_id](*inputs)\n",
    "        set_id = 1\n",
    "        set_voxel_inds = set_voxel_inds_tensor_shift_1[set_id:set_id+1].squeeze(0)\n",
    "        set_voxel_masks = set_voxel_masks_tensor_shift_1[set_id:set_id+1].squeeze(0)\n",
    "        pos_embed = pos_embed_tensor[blc_id:blc_id+1, set_id:set_id+1].squeeze(0).squeeze(0)\n",
    "        inputs = (outputs, set_voxel_inds, set_voxel_masks, pos_embed, True)\n",
    "        outputs = self.dsvtblocks_list[blc_id].encoder_list[set_id](*inputs)\n",
    "        \n",
    "        outputs = self.layer_norms_list[blc_id](residual + outputs)\n",
    "\n",
    "        return outputs\n",
    "####### DSVT #######\n",
    "\n",
    "####### torch to onnx #######\n",
    "with torch.no_grad():\n",
    "    DSVT_Backbone = model.backbone_3d\n",
    "    dsvtblocks_list = DSVT_Backbone.stage_0\n",
    "    layer_norms_list = DSVT_Backbone.residual_norm_stage_0\n",
    "    inputs = model.vfe(inputs)\n",
    "    voxel_info = DSVT_Backbone.input_layer(inputs)\n",
    "    set_voxel_inds_list = [[voxel_info[f'set_voxel_inds_stage{s}_shift{i}'] for i in range(2)] for s in range(1)]\n",
    "    set_voxel_masks_list = [[voxel_info[f'set_voxel_mask_stage{s}_shift{i}'] for i in range(2)] for s in range(1)]\n",
    "    pos_embed_list = [[[voxel_info[f'pos_embed_stage{s}_block{b}_shift{i}'] for i in range(2)] for b in range(4)] for s in range(1)]\n",
    "\n",
    "    pillar_features = inputs['voxel_features']\n",
    "    alldsvtblockstrt_inputs = (\n",
    "        pillar_features,\n",
    "        set_voxel_inds_list[0][0],\n",
    "        set_voxel_inds_list[0][1],\n",
    "        set_voxel_masks_list[0][0],\n",
    "        set_voxel_masks_list[0][1],\n",
    "        torch.stack([torch.stack(v, dim=0) for v in pos_embed_list[0]], dim=0),\n",
    "    )\n",
    "\n",
    "    jit_mode = \"trace\"\n",
    "    input_names = [\n",
    "        'src',\n",
    "        'set_voxel_inds_tensor_shift_0', \n",
    "        'set_voxel_inds_tensor_shift_1', \n",
    "        'set_voxel_masks_tensor_shift_0', \n",
    "        'set_voxel_masks_tensor_shift_1',\n",
    "        'pos_embed_tensor'\n",
    "    ]\n",
    "    output_names = [\"output\",]\n",
    "    input_shapes = {\n",
    "        \"src\": {\n",
    "            \"min_shape\": [24629, 192],\n",
    "            \"opt_shape\": [24629, 192],\n",
    "            \"max_shape\": [24629, 192],\n",
    "        },\n",
    "        \"set_voxel_inds_tensor_shift_0\": {\n",
    "            \"min_shape\": [2, 1156, 36],\n",
    "            \"opt_shape\": [2, 1156, 36],\n",
    "            \"max_shape\": [2, 1156, 36],\n",
    "        },\n",
    "        \"set_voxel_inds_tensor_shift_1\": {\n",
    "            \"min_shape\": [2, 834, 36],\n",
    "            \"opt_shape\": [2, 834, 36],\n",
    "            \"max_shape\": [2, 834, 36],\n",
    "        },\n",
    "        \"set_voxel_masks_tensor_shift_0\": {\n",
    "            \"min_shape\": [2, 1156, 36],\n",
    "            \"opt_shape\": [2, 1156, 36],\n",
    "            \"max_shape\": [2, 1156, 36],\n",
    "        },\n",
    "        \"set_voxel_masks_tensor_shift_1\": {\n",
    "            \"min_shape\": [2, 834, 36],\n",
    "            \"opt_shape\": [2, 834, 36],\n",
    "            \"max_shape\": [2, 834, 36],\n",
    "        },\n",
    "        \"pos_embed_tensor\": {\n",
    "            \"min_shape\": [4, 2, 24629, 192],\n",
    "            \"opt_shape\": [4, 2, 24629, 192],\n",
    "            \"max_shape\": [4, 2, 24629, 192],\n",
    "        },\n",
    "    }\n",
    "\n",
    "\n",
    "    dynamic_axes = {\n",
    "        \"src\": {\n",
    "            0: \"voxel_number\",\n",
    "        },\n",
    "        \"set_voxel_inds_tensor_shift_0\": {\n",
    "            1: \"set_number_shift_0\",\n",
    "        },\n",
    "        \"set_voxel_inds_tensor_shift_1\": {\n",
    "            1: \"set_number_shift_1\",\n",
    "        },\n",
    "        \"set_voxel_masks_tensor_shift_0\": {\n",
    "            1: \"set_number_shift_0\",\n",
    "        },\n",
    "        \"set_voxel_masks_tensor_shift_1\": {\n",
    "            1: \"set_number_shift_1\",\n",
    "        },\n",
    "        \"pos_embed_tensor\": {\n",
    "            2: \"voxel_number\",\n",
    "        },\n",
    "        \"output\": {\n",
    "            0: \"voxel_number\",\n",
    "        }\n",
    "    }\n",
    "\n",
    "    base_name = \"./deploy_pillar_sfaw_3d_origin/deploy_pillar_sfaw_3d_origin\"\n",
    "    ts_path = f\"{base_name}.ts\"\n",
    "    onnx_path = f\"{base_name}.onnx\"\n",
    "\n",
    "    allptransblocktrt = AllDSVTBlocksTRT(dsvtblocks_list, layer_norms_list).eval().cuda()\n",
    "    torch.onnx.export(\n",
    "        allptransblocktrt,\n",
    "        alldsvtblockstrt_inputs,\n",
    "        onnx_path, input_names=input_names,\n",
    "        output_names=output_names, dynamic_axes=dynamic_axes,\n",
    "        opset_version=14,\n",
    "    )\n",
    "    # test onnx\n",
    "    ort_session = ort.InferenceSession(onnx_path)\n",
    "    def to_numpy(tensor):\n",
    "        return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "    \n",
    "    # compute ONNX Runtime output prediction\n",
    "    ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(pillar_features),\n",
    "                  ort_session.get_inputs()[1].name: to_numpy(set_voxel_inds_list[0][0]),\n",
    "                  ort_session.get_inputs()[2].name: to_numpy(set_voxel_inds_list[0][1]),\n",
    "                  ort_session.get_inputs()[3].name: to_numpy(set_voxel_masks_list[0][0]),\n",
    "                  ort_session.get_inputs()[4].name: to_numpy(set_voxel_masks_list[0][1]),\n",
    "                  ort_session.get_inputs()[5].name: to_numpy(torch.stack([torch.stack(v, dim=0) for v in pos_embed_list[0]], dim=0)),}\n",
    "    import time\n",
    "    from onnxconverter_common import float16\n",
    "    \n",
    "    start_time = time.time()\n",
    "    ort_outs = ort_session.run(None, ort_inputs) \n",
    "    print(time.time()-start_time)\n",
    "    base_model = onnx.load(onnx_path)\n",
    "    model_fp16 = float16.convert_float_to_float16(base_model)\n",
    "    onnx.save(model_fp16, \"./deploy_pillar_sfaw_bm/dsvt_3d_onnx_16.onnx\")\n",
    "    onnx_path = \"./deploy_pillar_sfaw_bm/dsvt_3d_onnx_16.onnx\"\n",
    "    print(ort.get_device())\n",
    "    ort_session = ort.InferenceSession(onnx_path)\n",
    "    \n",
    "    \n",
    "    # # compute ONNX Runtime output prediction\n",
    "    ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(pillar_features).astype(np.float16),\n",
    "                  ort_session.get_inputs()[1].name: to_numpy(set_voxel_inds_list[0][0]).astype(np.int64),\n",
    "                  ort_session.get_inputs()[2].name: to_numpy(set_voxel_inds_list[0][1]).astype(np.int64),\n",
    "                  ort_session.get_inputs()[3].name: to_numpy(set_voxel_masks_list[0][0]),\n",
    "                  ort_session.get_inputs()[4].name: to_numpy(set_voxel_masks_list[0][1]),\n",
    "                  ort_session.get_inputs()[5].name: to_numpy(torch.stack([torch.stack(v, dim=0) for v in pos_embed_list[0]], dim=0)).astype(np.float16),}\n",
    "    \n",
    "    start_time = time.time()\n",
    "    ort_outs = ort_session.run(None, ort_inputs) \n",
    "    print(time.time()-start_time)\n",
    "    # model_fp16 = float16.convert_float_to_float16(ort_session)\n",
    "####### torch to onnx #######\n",
    "ort_outs\n",
    "\n",
    "####### torch to trt engine #######\n",
    "# trtexec --onnx={path to onnx} --saveEngine={path to save trtengine} \\\n",
    "# --memPoolSize=workspace:4096 --verbose --buildOnly --device=1 --fp16 \\\n",
    "# --tacticSources=+CUDNN,+CUBLAS,-CUBLAS_LT,+EDGE_MASK_CONVOLUTIONS \\\n",
    "# --minShapes=src:3000x192,set_voxel_inds_tensor_shift_0:2x170x36,set_voxel_inds_tensor_shift_1:2x100x36,set_voxel_masks_tensor_shift_0:2x170x36,set_voxel_masks_tensor_shift_1:2x100x36,pos_embed_tensor:4x2x3000x192 \\\n",
    "# --optShapes=src:20000x192,set_voxel_inds_tensor_shift_0:2x1000x36,set_voxel_inds_tensor_shift_1:2x700x36,set_voxel_masks_tensor_shift_0:2x1000x36,set_voxel_masks_tensor_shift_1:2x700x36,pos_embed_tensor:4x2x20000x192 \\\n",
    "# --maxShapes=src:35000x192,set_voxel_inds_tensor_shift_0:2x1500x36,set_voxel_inds_tensor_shift_1:2x1200x36,set_voxel_masks_tensor_shift_0:2x1500x36,set_voxel_masks_tensor_shift_1:2x1200x36,pos_embed_tensor:4x2x35000x192 \\\n",
    "####### torch to trt engine #######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4cefdc8-90a7-4e02-a885-3729f363ad74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_numpy(torch.stack([torch.stack(v, dim=0) for v in pos_embed_list[0]], dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfac36fb-fd95-47ae-861d-a2846c8e6a93",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'onnxruntime'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# !pip install onnxruntime\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01monnxruntime\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'onnxruntime'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34976db8-4cdb-48f3-bbcc-fd1d3f9f5fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([962, 192])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pillar_features.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ccdb739-a832-4a69-a870-2b5134105538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 40, 36])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_voxel_inds_list[0][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0abd2176-3235-463d-a8d0-dcc12ee498cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 34, 36])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_voxel_inds_list[0][1].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae2ad65a-3a05-4d2e-a652-50b705a3f258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX version: 1.16.0\n"
     ]
    }
   ],
   "source": [
    "print(\"ONNX version:\", onnx.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d27cf31e-40af-4cd2-a5df-41c99b55784e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.0.1+cu118\n"
     ]
    }
   ],
   "source": [
    "print(\"PyTorch version:\", torch.__version__)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
